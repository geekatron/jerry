# EN-002: Research Question Design (v2 - Redesigned)

> **Type:** enabler
> **Status:** completed
> **Priority:** critical
> **Impact:** critical
> **Enabler Type:** exploration
> **Created:** 2026-02-22T00:00:00Z
> **Due:** —
> **Completed:** 2026-02-22
> **Parent:** FEAT-002
> **Owner:** nse-requirements-002
> **Effort:** —

## Document Sections

| Section | Purpose |
|---------|---------|
| [Summary](#summary) | Enabler overview and output |
| [Problem Statement](#problem-statement) | Why this enabler is needed |
| [Business Value](#business-value) | Value delivered by this enabler |
| [Technical Approach](#technical-approach) | How the enabler will be executed |
| [Acceptance Criteria](#acceptance-criteria) | Conditions for completion |
| [Children (Tasks)](#children-tasks) | Task decomposition |
| [Progress Summary](#progress-summary) | Current progress status |
| [Evidence](#evidence) | Completion evidence and artifacts |
| [History](#history) | Change log |

---

## Summary

Research question design for redesigned A/B test. 15 questions across 5 domains (Sports, Technology, Science, History, Pop Culture) with 7-dimension scoring rubric. 10 ITS (Internal Training Susceptibility) questions targeting areas where training data is likely stale or inaccurate, plus 5 PC (Positive Control) questions with stable, well-known answers. Output via nse-requirements-002.

## Problem Statement

The v1 A/B test used only 5 questions, which limited statistical power and domain coverage. A redesigned question set with broader domain coverage and explicit ground truth baselines is needed to produce defensible comparative results.

## Business Value

Provides the foundational question set and scoring methodology that all downstream A/B test agents depend on. Without well-designed questions targeting known vulnerability areas, the test cannot reliably detect the stale data problem.

## Technical Approach

nse-requirements-002 agent designs 15 research questions: 10 ITS questions targeting domains where LLM training data is known to be stale or incomplete, and 5 PC questions with stable, verifiable answers. A 7-dimension scoring rubric is defined for consistent evaluation across all responses.

## Acceptance Criteria

- [x] 15 questions designed across 5 domains (Sports, Technology, Science, History, Pop Culture)
- [x] 10 ITS questions targeting stale/inaccurate training data areas
- [x] 5 PC (Positive Control) questions with stable, well-known answers
- [x] 7-dimension scoring rubric defined
- [x] Questions reviewed and approved for A/B test execution

## Children (Tasks)

None.

## Progress Summary

Completed. 15 questions designed with 7-dimension scoring rubric. Question set approved for A/B test execution.

## Evidence

| Artifact | Path |
|----------|------|
| Primary output | `orchestration/llm-deception-20260222-002/ps/phase-2-ab-test/nse-requirements-002/nse-requirements-002-output.md` |
| Quality gate | `orchestration/llm-deception-20260222-002/quality-gates/qg-2/qg-2-report.md` |

## History

| Date | Change |
|------|--------|
| 2026-02-22 | Created -- research question design enabler for v2 A/B test |
| 2026-02-22 | Completed -- 15 questions across 5 domains with 7-dimension scoring rubric. 10 ITS + 5 PC questions designed and approved. |
