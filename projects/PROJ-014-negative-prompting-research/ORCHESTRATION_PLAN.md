# PROJ-014 Negative Prompting Research: Orchestration Plan

> **Document ID:** PROJ-014-ORCH-PLAN
> **Workflow ID:** `neg-prompting-20260227-001`
> **Date:** 2026-02-27
> **Status:** PLANNED
> **Criticality:** C4 (Critical)
> **Quality Threshold:** >= 0.95 (all phases and barriers)

> **Disclaimer:** This orchestration plan was generated by orch-planner agent (v2.2.0). Human review recommended before execution. All paths are repository-relative and cross-session portable. Execution state is authoritative in `ORCHESTRATION.yaml`.

---

## Document Sections

| Section | Purpose |
|---------|---------|
| [L0: Workflow Overview](#l0-workflow-overview) | Plain-language summary for stakeholders |
| [L1: Technical Plan](#l1-technical-plan) | Workflow diagram, phase definitions, agent assignments, barriers |
| [L2: Implementation Details](#l2-implementation-details) | State schema, path configuration, recovery strategies |
| [Session Entry Prompts](#session-entry-prompts) | Copy-paste prompts for running each phase in a fresh session |
| [Quality Gate Configuration](#quality-gate-configuration) | C4 adversarial strategy set, thresholds, iteration caps |

---

## L0: Workflow Overview

This workflow answers a single question: does telling LLMs what NOT to do work better than telling them what to do? The hypothesis is that negative unambiguous prompting — "never use jargon" instead of "write professionally" — reduces hallucination by 60% and produces better instruction-following than equivalent positive prompts.

The research has direct consequences for the Jerry framework. If the hypothesis holds, every Jerry rule file, agent definition, skill description, and prompt template should be rewritten to use negative constraints rather than positive directives. That is a large change touching the entire framework, so it requires rigorous evidence-based validation before implementation.

The workflow runs six sequential phases. Three parallel literature researchers gather 50+ sources in Phase 1. Two analysts validate and compare claims in Phase 2. A taxonomy of negative prompting patterns is built in Phase 3. Five parallel analysts assess how Jerry's skills, agents, rules, patterns, and templates would each need to change in Phase 4. An architect produces ADRs in Phase 5. A final synthesis and C4 tournament quality review closes in Phase 6.

**Quality model: per-agent adversary gates.** Every creator agent output goes through its own /adversary C4 gate immediately after production -- no creator output flows downstream ungated. Each gate uses the 3-agent adversary pipeline (adv-selector, adv-executor, adv-scorer) with all 10 C4 strategies, a >= 0.95 threshold, and a maximum of 5 iterations. When the adversary finds issues, the creator agent is re-invoked with the findings to revise (never in the main context window). Only after a creator output passes its gate does it flow to the next step or barrier. Barriers then run their own adversary gate on the cross-pollination synthesis, which operates on already-gated inputs. This means the workflow has 23 quality gates total: 17 per-agent gates, 5 barrier synthesis gates, and 1 final C4 tournament.

---

## L1: Technical Plan

### Workflow Diagram (ASCII)

```
PROJ-014: Negative Prompting Research
Workflow ID: neg-prompting-20260227-001
Single Pipeline (ps) with PER-AGENT /adversary C4 gates on EVERY creator output
+ /adversary C4 gates on EVERY barrier synthesis + C4 Tournament at end
C4 Criticality — All 10 strategies required — 3-agent adversary pipeline
(adv-selector -> adv-executor -> adv-scorer) — 23 total quality gates

ADVERSARY GATE PATTERN (applies to every creator agent and every barrier synthesis):
┌────────────────────────────────────────────────────────────────────┐
│  Creator produces output                                           │
│  -> adv-selector: maps C4 to all 10 strategies                    │
│  -> adv-executor: executes strategy templates against deliverable  │
│  -> adv-scorer: scores via S-014 (6 dims, weighted composite)     │
│  -> IF score < 0.95 AND iteration < 5:                            │
│       Re-invoke creator agent with findings (in agent context)     │
│       NEVER address feedback in main context window                │
│  -> IF score >= 0.95: PASS — proceed downstream                   │
│  -> IF score < 0.95 after 5 iterations: STOP — escalate to user   │
└────────────────────────────────────────────────────────────────────┘

┌──────────────────────────────────────────────────────────────────────────────────┐
│ PHASE 1: LITERATURE RESEARCH (PARALLEL fan-out)                                  │
│ ──────────────────────────────────────────────────────────────────────────────── │
│                                                                                  │
│  [ps-researcher-001] (PARALLEL)          [ps-researcher-002] (PARALLEL)         │
│   Academic papers on negative             Industry/practitioner sources          │
│   prompting, constraint-based             Vendor docs, blog posts, empirical    │
│   prompting, "don't" instructions         reports on negative vs positive       │
│   25+ sources via WebSearch/Fetch         25+ sources via WebSearch/Fetch       │
│   Output: research/academic-survey.md    Output: research/industry-survey.md    │
│      ┌──────────────────────────┐           ┌──────────────────────────┐        │
│      │ /adversary C4 GATE      │           │ /adversary C4 GATE      │        │
│      │ adv-selector->executor  │           │ adv-selector->executor  │        │
│      │ ->scorer >= 0.95, 5 iter│           │ ->scorer >= 0.95, 5 iter│        │
│      │ FAIL: re-invoke creator │           │ FAIL: re-invoke creator │        │
│      └──────────────────────────┘           └──────────────────────────┘        │
│                                                                                  │
│  [ps-researcher-003] (PARALLEL)                                                  │
│   Context7 library documentation          Tools: resolve-library-id + query-docs │
│   Anthropic Claude docs, OpenAI docs,    Libraries: Anthropic, OpenAI,          │
│   LangChain, prompt engineering           LangChain, prompt-engineering-guide    │
│   frameworks for negative prompting      Output: research/context7-survey.md    │
│      ┌──────────────────────────┐                                                │
│      │ /adversary C4 GATE      │                                                │
│      │ adv-selector->executor  │                                                │
│      │ ->scorer >= 0.95, 5 iter│                                                │
│      │ FAIL: re-invoke creator │                                                │
│      └──────────────────────────┘                                                │
│                                                                                  │
│ STATUS: NOT STARTED | AGENT GATES: 3 (one per researcher)                        │
└──────────────────────────────────┬───────────────────────────────────────────────┘
                                   │ (all 3 outputs quality-gated)
                                   ▼
╔════════════════════════════════════════════════════════════════════════════════════╗
║                            BARRIER 1: RESEARCH CROSS-POLLINATION                  ║
║  ┌────────────────────────────────────────────────────────────────────────────┐   ║
║  │  INPUT: 3 ALREADY quality-gated research outputs                          │   ║
║  │  ps-synthesizer-001 cross-pollinates 3 research outputs                   │   ║
║  │  /adversary C4 quality gate on synthesis (adv-selector->executor->scorer) │   ║
║  │  GATE REQUIREMENTS:                                                        │   ║
║  │    - Score >= 0.95 (up to 5 iterations)                                   │   ║
║  │    - FAIL: re-invoke ps-synthesizer-001 with findings                     │   ║
║  │    - Verify: 50+ unique sources cited                                      │   ║
║  │    - Verify: No unsourced claims                                           │   ║
║  │    - Verify: No training-data-only assertions                              │   ║
║  │  Output: orchestration/neg-prompting-20260227-001/barrier-1/synthesis.md  │   ║
║  └────────────────────────────────────────────────────────────────────────────┘   ║
║  STATUS: NOT STARTED                                                              ║
╚════════════════════════════════════════════════════════════════════════════════════╝
                                   │
                                   ▼
┌──────────────────────────────────────────────────────────────────────────────────┐
│ PHASE 2: EVIDENCE ANALYSIS (PARALLEL)                                            │
│ ──────────────────────────────────────────────────────────────────────────────── │
│                                                                                  │
│  [ps-analyst-001] (PARALLEL)              [ps-analyst-002] (PARALLEL)           │
│   Validate the 60% hallucination          Comparative effectiveness analysis    │
│   reduction claim: trace to primary       Positive vs negative prompting        │
│   sources, assess methodology,            across dimensions: accuracy,          │
│   identify conditions/limitations         compliance, hallucination,            │
│   Input: Barrier 1 synthesis             instruction-following, creativity      │
│   Output: analysis/claim-validation.md   Input: Barrier 1 synthesis            │
│      ┌──────────────────────────┐        Output: analysis/comparative.md       │
│      │ /adversary C4 GATE      │           ┌──────────────────────────┐        │
│      │ adv-selector->executor  │           │ /adversary C4 GATE      │        │
│      │ ->scorer >= 0.95, 5 iter│           │ adv-selector->executor  │        │
│      │ FAIL: re-invoke creator │           │ ->scorer >= 0.95, 5 iter│        │
│      └──────────────────────────┘           │ FAIL: re-invoke creator │        │
│                                             └──────────────────────────┘        │
│                                                                                  │
│ STATUS: NOT STARTED | AGENT GATES: 2 (one per analyst)                           │
└──────────────────────────────────┬───────────────────────────────────────────────┘
                                   │ (both outputs quality-gated)
                                   ▼
╔════════════════════════════════════════════════════════════════════════════════════╗
║                            BARRIER 2: ANALYSIS CROSS-POLLINATION                  ║
║  ┌────────────────────────────────────────────────────────────────────────────┐   ║
║  │  INPUT: 2 ALREADY quality-gated analysis outputs                          │   ║
║  │  ps-synthesizer-002 cross-pollinates 2 analysis outputs                   │   ║
║  │  /adversary C4 quality gate on synthesis (adv-selector->executor->scorer) │   ║
║  │  GATE REQUIREMENTS:                                                        │   ║
║  │    - Score >= 0.95 (up to 5 iterations)                                   │   ║
║  │    - FAIL: re-invoke ps-synthesizer-002 with findings                     │   ║
║  │    - All claims traced to primary sources                                  │   ║
║  │    - Claim validation includes methodology assessment                      │   ║
║  │    - Comparative analysis covers all 5 dimensions                         │   ║
║  │  Output: orchestration/neg-prompting-20260227-001/barrier-2/synthesis.md  │   ║
║  └────────────────────────────────────────────────────────────────────────────┘   ║
║  STATUS: NOT STARTED                                                              ║
╚════════════════════════════════════════════════════════════════════════════════════╝
                                   │
                                   ▼
┌──────────────────────────────────────────────────────────────────────────────────┐
│ PHASE 3: NEGATIVE PROMPTING TAXONOMY (SEQUENTIAL)                                │
│ ──────────────────────────────────────────────────────────────────────────────── │
│                                                                                  │
│  [ps-analyst-003] (STEP 1)                                                       │
│   Build taxonomy of negative prompting patterns                                  │
│   Types, when each works, when each fails, evidence basis                        │
│   Input: Barrier 2 synthesis                                                     │
│   Output: analysis/taxonomy.md                                                   │
│      ┌──────────────────────────┐                                                │
│      │ /adversary C4 GATE      │                                                │
│      │ adv-selector->executor  │                                                │
│      │ ->scorer >= 0.95, 5 iter│                                                │
│      │ FAIL: re-invoke creator │                                                │
│      └───────────┬──────────────┘                                                │
│                   │ (gated taxonomy.md)                                           │
│                   ▼                                                               │
│  [ps-architect-001] (STEP 2)                                                     │
│   Design negative prompting pattern catalog for Jerry                            │
│   Map taxonomy patterns to Jerry's constraint language                           │
│   Input: analysis/taxonomy.md (gated) + Barrier 2 synthesis                     │
│   Output: decisions/pattern-catalog.md                                           │
│      ┌──────────────────────────┐                                                │
│      │ /adversary C4 GATE      │                                                │
│      │ adv-selector->executor  │                                                │
│      │ ->scorer >= 0.95, 5 iter│                                                │
│      │ FAIL: re-invoke creator │                                                │
│      └──────────────────────────┘                                                │
│                                                                                  │
│ STATUS: NOT STARTED | AGENT GATES: 2 (one per agent)                             │
└──────────────────────────────────┬───────────────────────────────────────────────┘
                                   │ (both outputs quality-gated)
                                   ▼
╔════════════════════════════════════════════════════════════════════════════════════╗
║                            BARRIER 3: TAXONOMY QUALITY GATE                       ║
║  ┌────────────────────────────────────────────────────────────────────────────┐   ║
║  │  INPUT: ALREADY quality-gated taxonomy.md + pattern-catalog.md            │   ║
║  │  /adversary C4 gate on cross-artifact coherence                           │   ║
║  │  (adv-selector -> adv-executor -> adv-scorer)                             │   ║
║  │  GATE REQUIREMENTS:                                                        │   ║
║  │    - Score >= 0.95 (up to 5 iterations)                                   │   ║
║  │    - FAIL: re-invoke ps-analyst-003 / ps-architect-001 with findings      │   ║
║  │    - Taxonomy covers all pattern types evidenced in research               │   ║
║  │    - Pattern catalog is actionable for Jerry                               │   ║
║  │    - Each pattern has evidence basis from literature                       │   ║
║  │  Output: orchestration/neg-prompting-20260227-001/barrier-3/gate.md       │   ║
║  └────────────────────────────────────────────────────────────────────────────┘   ║
║  STATUS: NOT STARTED                                                              ║
╚════════════════════════════════════════════════════════════════════════════════════╝
                                   │
                                   ▼
┌──────────────────────────────────────────────────────────────────────────────────┐
│ PHASE 4: JERRY APPLICATION ANALYSIS (PARALLEL fan-out)                           │
│ ──────────────────────────────────────────────────────────────────────────────── │
│                                                                                  │
│  [ps-analyst-004] (PARALLEL)              [ps-analyst-005] (PARALLEL)           │
│   Skills update analysis                  Agents update analysis                │
│   Read: skills/*/SKILL.md                 Read: skills/*/agents/*.md            │
│   Output: analysis/skills-analysis.md    Output: analysis/agents-analysis.md   │
│      ┌──────────────────────────┐           ┌──────────────────────────┐        │
│      │ /adversary C4 GATE      │           │ /adversary C4 GATE      │        │
│      │ adv-selector->executor  │           │ adv-selector->executor  │        │
│      │ ->scorer >= 0.95, 5 iter│           │ ->scorer >= 0.95, 5 iter│        │
│      │ FAIL: re-invoke creator │           │ FAIL: re-invoke creator │        │
│      └──────────────────────────┘           └──────────────────────────┘        │
│                                                                                  │
│  [ps-analyst-006] (PARALLEL)              [ps-analyst-007] (PARALLEL)           │
│   Rules update analysis                   Patterns update analysis              │
│   Read: .context/rules/*.md              Read: docs/knowledge/*.md              │
│   Output: analysis/rules-analysis.md     Output: analysis/patterns-analysis.md │
│      ┌──────────────────────────┐           ┌──────────────────────────┐        │
│      │ /adversary C4 GATE      │           │ /adversary C4 GATE      │        │
│      │ adv-selector->executor  │           │ adv-selector->executor  │        │
│      │ ->scorer >= 0.95, 5 iter│           │ ->scorer >= 0.95, 5 iter│        │
│      │ FAIL: re-invoke creator │           │ FAIL: re-invoke creator │        │
│      └──────────────────────────┘           └──────────────────────────┘        │
│                                                                                  │
│  [ps-analyst-008] (PARALLEL)                                                     │
│   Templates update analysis                                                      │
│   Read: .context/templates/**/*                                                  │
│   Output: analysis/templates-analysis.md                                         │
│      ┌──────────────────────────┐                                                │
│      │ /adversary C4 GATE      │                                                │
│      │ adv-selector->executor  │                                                │
│      │ ->scorer >= 0.95, 5 iter│                                                │
│      │ FAIL: re-invoke creator │                                                │
│      └──────────────────────────┘                                                │
│                                                                                  │
│ ALL AGENTS: Input from Barrier 3 approved artifacts                              │
│ STATUS: NOT STARTED | AGENT GATES: 5 (one per analyst)                           │
└──────────────────────────────────┬───────────────────────────────────────────────┘
                                   │ (all 5 outputs quality-gated)
                                   ▼
╔════════════════════════════════════════════════════════════════════════════════════╗
║                            BARRIER 4: APPLICATION CROSS-POLLINATION               ║
║  ┌────────────────────────────────────────────────────────────────────────────┐   ║
║  │  INPUT: 5 ALREADY quality-gated application analyses                      │   ║
║  │  ps-synthesizer-003 cross-pollinates all 5 application analyses           │   ║
║  │  /adversary C4 quality gate on synthesis (adv-selector->executor->scorer) │   ║
║  │  GATE REQUIREMENTS:                                                        │   ║
║  │    - Score >= 0.95 (up to 5 iterations)                                   │   ║
║  │    - FAIL: re-invoke ps-synthesizer-003 with findings                     │   ║
║  │    - Cross-domain conflicts identified and resolved                        │   ║
║  │    - Each recommendation traceable to taxonomy + literature               │   ║
║  │    - Prioritization applied across all 5 domains                          │   ║
║  │  Output: orchestration/neg-prompting-20260227-001/barrier-4/synthesis.md  │   ║
║  └────────────────────────────────────────────────────────────────────────────┘   ║
║  STATUS: NOT STARTED                                                              ║
╚════════════════════════════════════════════════════════════════════════════════════╝
                                   │
                                   ▼
┌──────────────────────────────────────────────────────────────────────────────────┐
│ PHASE 5: IMPLEMENTATION PLANNING (SEQUENTIAL)                                    │
│ ──────────────────────────────────────────────────────────────────────────────── │
│                                                                                  │
│  [ps-architect-002] (STEP 1)                                                     │
│   Create ADR: How to apply negative prompting to Jerry skills                    │
│   Output: decisions/ADR-014-001-skills-negative-prompting.md                    │
│      ┌──────────────────────────┐                                                │
│      │ /adversary C4 GATE      │                                                │
│      │ adv-selector->executor  │                                                │
│      │ ->scorer >= 0.95, 5 iter│                                                │
│      │ FAIL: re-invoke creator │                                                │
│      └───────────┬──────────────┘                                                │
│                   │ (gated ADR-014-001)                                           │
│                   ▼                                                               │
│  [ps-architect-003] (STEP 2)                                                     │
│   Create ADR: How to update Jerry agent definitions                              │
│   Output: decisions/ADR-014-002-agents-negative-prompting.md                    │
│      ┌──────────────────────────┐                                                │
│      │ /adversary C4 GATE      │                                                │
│      │ adv-selector->executor  │                                                │
│      │ ->scorer >= 0.95, 5 iter│                                                │
│      │ FAIL: re-invoke creator │                                                │
│      └───────────┬──────────────┘                                                │
│                   │ (gated ADR-014-002)                                           │
│                   ▼                                                               │
│  [ps-architect-004] (STEP 3)                                                     │
│   Create ADR: How to update Jerry rules                                          │
│   Escalation: AE-002 + AE-003 apply                                             │
│   Output: decisions/ADR-014-003-rules-negative-prompting.md                     │
│      ┌──────────────────────────┐                                                │
│      │ /adversary C4 GATE      │                                                │
│      │ adv-selector->executor  │                                                │
│      │ ->scorer >= 0.95, 5 iter│                                                │
│      │ FAIL: re-invoke creator │                                                │
│      └───────────┬──────────────┘                                                │
│                   │ (gated ADR-014-003)                                           │
│                   ▼                                                               │
│  [ps-architect-005] (STEP 4)                                                     │
│   Create ADR: How to update Jerry patterns and templates                         │
│   Output: decisions/ADR-014-004-patterns-templates-negative-prompting.md        │
│      ┌──────────────────────────┐                                                │
│      │ /adversary C4 GATE      │                                                │
│      │ adv-selector->executor  │                                                │
│      │ ->scorer >= 0.95, 5 iter│                                                │
│      │ FAIL: re-invoke creator │                                                │
│      └──────────────────────────┘                                                │
│                                                                                  │
│ STATUS: NOT STARTED | AGENT GATES: 4 (one per architect)                         │
└──────────────────────────────────┬───────────────────────────────────────────────┘
                                   │ (all 4 ADRs quality-gated)
                                   ▼
╔════════════════════════════════════════════════════════════════════════════════════╗
║                            BARRIER 5: IMPLEMENTATION QUALITY GATE                 ║
║  ┌────────────────────────────────────────────────────────────────────────────┐   ║
║  │  INPUT: 4 ALREADY quality-gated ADRs                                      │   ║
║  │  /adversary C4 gate on cross-ADR coherence                                │   ║
║  │  (adv-selector -> adv-executor -> adv-scorer)                             │   ║
║  │  GATE REQUIREMENTS:                                                        │   ║
║  │    - Score >= 0.95 (up to 5 iterations)                                   │   ║
║  │    - FAIL: re-invoke relevant ps-architect with findings                  │   ║
║  │    - All ADRs in Nygard format                                             │   ║
║  │    - All options analyzed with trade-offs                                  │   ║
║  │    - Decisions traceable to evidence                                       │   ║
║  │    - Consequences section covers positive and negative outcomes            │   ║
║  │  Output: orchestration/neg-prompting-20260227-001/barrier-5/gate.md       │   ║
║  └────────────────────────────────────────────────────────────────────────────┘   ║
║  STATUS: NOT STARTED                                                              ║
╚════════════════════════════════════════════════════════════════════════════════════╝
                                   │
                                   ▼
┌──────────────────────────────────────────────────────────────────────────────────┐
│ PHASE 6: FINAL SYNTHESIS + C4 TOURNAMENT (SEQUENTIAL)                            │
│ ──────────────────────────────────────────────────────────────────────────────── │
│                                                                                  │
│  [ps-synthesizer-004] (STEP 1)                                                   │
│   Unified synthesis: all findings from Phases 1-5                                │
│   Input: All barrier synthesis files + all ADRs                                  │
│   Output: synthesis/final-synthesis.md                                           │
│      ┌──────────────────────────┐                                                │
│      │ /adversary C4 GATE      │                                                │
│      │ adv-selector->executor  │                                                │
│      │ ->scorer >= 0.95, 5 iter│                                                │
│      │ FAIL: re-invoke creator │                                                │
│      └───────────┬──────────────┘                                                │
│                   │ (gated final-synthesis.md)                                    │
│                   ▼                                                               │
│  [ps-architect-006] (STEP 2)                                                     │
│   Final implementation roadmap with priorities                                   │
│   Phased plan: what to change first, second, third                               │
│   Output: synthesis/implementation-roadmap.md                                    │
│      ┌──────────────────────────┐                                                │
│      │ /adversary C4 GATE      │                                                │
│      │ adv-selector->executor  │                                                │
│      │ ->scorer >= 0.95, 5 iter│                                                │
│      │ FAIL: re-invoke creator │                                                │
│      └───────────┬──────────────┘                                                │
│                   │ (gated implementation-roadmap.md)                             │
│                   ▼                                                               │
│  [/adversary C4 TOURNAMENT] (STEP 3)                                             │
│   ALL 10 strategies executed against gated final-synthesis.md +                  │
│   gated implementation-roadmap.md                                                │
│   adv-selector -> adv-executor -> adv-scorer (full tournament)                   │
│   S-014, S-003, S-013, S-007, S-002, S-004, S-010, S-012, S-011, S-001         │
│   Score >= 0.95, up to 5 iterations                                              │
│   FAIL: re-invoke ps-synthesizer-004 / ps-architect-006 with findings           │
│   Output: orchestration/neg-prompting-20260227-001/adversary/c4-tournament/     │
│                                                                                  │
│ STATUS: NOT STARTED | AGENT GATES: 2 + TOURNAMENT: 1                             │
└──────────────────────────────────┬───────────────────────────────────────────────┘
                                   │
                                   ▼
                        ╔══════════════════════╗
                        ║   WORKFLOW DONE      ║
                        ║   PASS: >= 0.95      ║
                        ║   23 gates passed    ║
                        ╚══════════════════════╝
```

### Workflow Diagram (Mermaid)

```mermaid
graph TD
    %% ============================================================
    %% PROJ-014: Negative Prompting Research — Full Workflow Diagram
    %% Workflow ID: neg-prompting-20260227-001
    %% Criticality: C4 | Quality Threshold: >= 0.95 all gates
    %% 6 Phases | 5 Barriers | 17 Creator Agents | 23 Quality Gates
    %% Quality Model: PER-AGENT adversary gates (3-agent pipeline)
    %% adv-selector -> adv-executor -> adv-scorer at EVERY output
    %% Feedback: re-invoke creator agent, NEVER main context
    %% ============================================================

    START(["PROJ-014: Negative Prompting Research<br/>Workflow: neg-prompting-20260227-001<br/>Criticality: C4 | Threshold: >= 0.95<br/>Quality Model: Per-Agent Adversary Gates<br/>23 total gates: 17 agent + 5 barrier + 1 tournament"])

    %% ============================================================
    %% PHASE 1: LITERATURE RESEARCH (PARALLEL fan-out, 3 agents)
    %% Each agent has its own /adversary C4 gate immediately after output
    %% ============================================================
    subgraph PHASE1["PHASE 1: Literature Research (PARALLEL fan-out) — 3 agent gates"]
        direction TB
        style PHASE1 fill:#1e3a5f,stroke:#4a90d9,color:#ffffff,stroke-width:2px

        P1_R1["<b>ps-researcher-001</b><br/>Academic papers on negative prompting,<br/>constraint-based prompting, dont instructions<br/><i>Data: WebSearch + WebFetch</i><br/><i>Target: 25+ sources</i><br/>TASK-001"]
        P1_R1_GATE{"<b>/adversary C4 Gate</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke ps-researcher-001"}
        P1_R1_OUT["GATED: research/academic-survey.md"]

        P1_R2["<b>ps-researcher-002</b><br/>Industry/practitioner sources:<br/>vendor docs, blog posts, empirical reports<br/>on negative vs positive prompting<br/><i>Data: WebSearch + WebFetch</i><br/><i>Target: 25+ sources</i><br/>TASK-002"]
        P1_R2_GATE{"<b>/adversary C4 Gate</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke ps-researcher-002"}
        P1_R2_OUT["GATED: research/industry-survey.md"]

        P1_R3["<b>ps-researcher-003</b><br/>Context7 library documentation:<br/>Anthropic, OpenAI, LangChain,<br/>LlamaIndex, DSPy<br/><i>Data: Context7 resolve-library-id + query-docs</i><br/><i>Fallback: WebSearch</i><br/>TASK-003"]
        P1_R3_GATE{"<b>/adversary C4 Gate</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke ps-researcher-003"}
        P1_R3_OUT["GATED: research/context7-survey.md"]

        P1_R1 --> P1_R1_GATE
        P1_R1_GATE -->|"PASS >= 0.95"| P1_R1_OUT
        P1_R1_GATE -->|"FAIL < 0.95 iter < 5"| P1_R1

        P1_R2 --> P1_R2_GATE
        P1_R2_GATE -->|"PASS >= 0.95"| P1_R2_OUT
        P1_R2_GATE -->|"FAIL < 0.95 iter < 5"| P1_R2

        P1_R3 --> P1_R3_GATE
        P1_R3_GATE -->|"PASS >= 0.95"| P1_R3_OUT
        P1_R3_GATE -->|"FAIL < 0.95 iter < 5"| P1_R3
    end

    START --> PHASE1

    P1_R1_OUT -->|"gated academic-survey.md"| B1_IN
    P1_R2_OUT -->|"gated industry-survey.md"| B1_IN
    P1_R3_OUT -->|"gated context7-survey.md"| B1_IN

    %% ============================================================
    %% BARRIER 1: RESEARCH CROSS-POLLINATION (on already-gated inputs)
    %% ============================================================
    subgraph BARRIER1["BARRIER 1: Research Cross-Pollination (gated inputs)"]
        direction TB
        style BARRIER1 fill:#5c2d00,stroke:#ff8c00,color:#ffffff,stroke-width:3px

        B1_IN{{"Fan-in: 3 ALREADY GATED research outputs"}}
        B1_SYNTH["<b>ps-synthesizer-001</b><br/>Cross-pollinate 3 gated research outputs<br/>into unified research synthesis<br/>TASK-004"]
        B1_GATE{"<b>/adversary C4 Gate on Synthesis</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke ps-synthesizer-001<br/><b>Checks:</b><br/>- 50+ unique sources cited<br/>- No unsourced claims<br/>- No training-data-only assertions<br/>- Source quality appropriate"}
        B1_OUT["barrier-1/synthesis.md<br/>+ barrier-1/adversary-gate.md"]

        B1_IN --> B1_SYNTH
        B1_SYNTH --> B1_GATE
        B1_GATE -->|"PASS >= 0.95"| B1_OUT
        B1_GATE -->|"FAIL < 0.95 iter < 5"| B1_SYNTH
    end

    %% ============================================================
    %% PHASE 2: EVIDENCE ANALYSIS (PARALLEL, 2 agents, each with gate)
    %% ============================================================
    subgraph PHASE2["PHASE 2: Evidence Analysis (PARALLEL fan-out) — 2 agent gates"]
        direction TB
        style PHASE2 fill:#1e3a5f,stroke:#4a90d9,color:#ffffff,stroke-width:2px

        P2_A1["<b>ps-analyst-001</b><br/>Validate 60% hallucination reduction claim:<br/>trace to primary sources, assess methodology,<br/>identify conditions and limitations<br/><i>Data: Barrier 1 synthesis + WebSearch + WebFetch</i><br/>TASK-005"]
        P2_A1_GATE{"<b>/adversary C4 Gate</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke ps-analyst-001"}
        P2_A1_OUT["GATED: analysis/claim-validation.md"]

        P2_A2["<b>ps-analyst-002</b><br/>Comparative effectiveness analysis:<br/>positive vs negative prompting across<br/>5 dimensions: accuracy, compliance,<br/>hallucination, instruction-following, creativity<br/><i>Data: Barrier 1 synthesis + WebSearch + WebFetch</i><br/>TASK-006"]
        P2_A2_GATE{"<b>/adversary C4 Gate</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke ps-analyst-002"}
        P2_A2_OUT["GATED: analysis/comparative.md"]

        P2_A1 --> P2_A1_GATE
        P2_A1_GATE -->|"PASS >= 0.95"| P2_A1_OUT
        P2_A1_GATE -->|"FAIL < 0.95 iter < 5"| P2_A1

        P2_A2 --> P2_A2_GATE
        P2_A2_GATE -->|"PASS >= 0.95"| P2_A2_OUT
        P2_A2_GATE -->|"FAIL < 0.95 iter < 5"| P2_A2
    end

    B1_OUT --> PHASE2

    P2_A1_OUT -->|"gated claim-validation.md"| B2_IN
    P2_A2_OUT -->|"gated comparative.md"| B2_IN

    %% ============================================================
    %% BARRIER 2: ANALYSIS CROSS-POLLINATION (on already-gated inputs)
    %% ============================================================
    subgraph BARRIER2["BARRIER 2: Analysis Cross-Pollination (gated inputs)"]
        direction TB
        style BARRIER2 fill:#5c2d00,stroke:#ff8c00,color:#ffffff,stroke-width:3px

        B2_IN{{"Fan-in: 2 ALREADY GATED analysis outputs"}}
        B2_SYNTH["<b>ps-synthesizer-002</b><br/>Cross-pollinate 2 gated analysis outputs<br/>into unified analysis synthesis<br/>TASK-007"]
        B2_GATE{"<b>/adversary C4 Gate on Synthesis</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke ps-synthesizer-002<br/><b>Checks:</b><br/>- All claims traced to primary sources<br/>- Claim validation includes methodology critique<br/>- Comparative covers all 5 dimensions<br/>- Contradictions resolved or documented"}
        B2_OUT["barrier-2/synthesis.md<br/>+ barrier-2/adversary-gate.md"]

        B2_IN --> B2_SYNTH
        B2_SYNTH --> B2_GATE
        B2_GATE -->|"PASS >= 0.95"| B2_OUT
        B2_GATE -->|"FAIL < 0.95 iter < 5"| B2_SYNTH
    end

    %% ============================================================
    %% PHASE 3: NEGATIVE PROMPTING TAXONOMY (SEQUENTIAL, 2 agents, each with gate)
    %% ============================================================
    subgraph PHASE3["PHASE 3: Negative Prompting Taxonomy (SEQUENTIAL) — 2 agent gates"]
        direction TB
        style PHASE3 fill:#1e3a5f,stroke:#4a90d9,color:#ffffff,stroke-width:2px

        P3_A3["<b>ps-analyst-003</b> — STEP 1<br/>Build taxonomy of negative prompting patterns:<br/>types, when each works, when each fails,<br/>evidence basis for each pattern<br/><i>Data: Barrier 2 synthesis</i><br/>TASK-008"]
        P3_A3_GATE{"<b>/adversary C4 Gate</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke ps-analyst-003"}
        P3_A3_OUT["GATED: analysis/taxonomy.md"]

        P3_AR1["<b>ps-architect-001</b> — STEP 2<br/>Design negative prompting pattern catalog<br/>for Jerry framework: map taxonomy patterns<br/>to Jerry constraint language<br/><i>Data: GATED taxonomy.md + Barrier 2 synthesis</i><br/>TASK-008"]
        P3_AR1_GATE{"<b>/adversary C4 Gate</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke ps-architect-001"}
        P3_AR1_OUT["GATED: decisions/pattern-catalog.md"]

        P3_A3 --> P3_A3_GATE
        P3_A3_GATE -->|"PASS >= 0.95"| P3_A3_OUT
        P3_A3_GATE -->|"FAIL < 0.95 iter < 5"| P3_A3
        P3_A3_OUT --> P3_AR1
        P3_AR1 --> P3_AR1_GATE
        P3_AR1_GATE -->|"PASS >= 0.95"| P3_AR1_OUT
        P3_AR1_GATE -->|"FAIL < 0.95 iter < 5"| P3_AR1
    end

    B2_OUT --> PHASE3

    P3_AR1_OUT -->|"gated pattern-catalog.md"| B3_IN

    %% ============================================================
    %% BARRIER 3: TAXONOMY QUALITY GATE (on already-gated inputs)
    %% ============================================================
    subgraph BARRIER3["BARRIER 3: Taxonomy Quality Gate (gated inputs)"]
        direction TB
        style BARRIER3 fill:#5c2d00,stroke:#ff8c00,color:#ffffff,stroke-width:3px

        B3_IN{{"Gate input: GATED taxonomy.md + GATED pattern-catalog.md"}}
        B3_GATE{"<b>/adversary C4 Gate on Cross-Artifact Coherence</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke ps-analyst-003 / ps-architect-001<br/><b>Checks:</b><br/>- Taxonomy covers all pattern types in research<br/>- Each pattern has evidence basis<br/>- Catalog actionable for Jerry<br/>- Catalog templates concrete<br/>- Anti-patterns section present"}
        B3_OUT["barrier-3/gate.md"]

        B3_IN --> B3_GATE
        B3_GATE -->|"PASS >= 0.95"| B3_OUT
        B3_GATE -->|"FAIL < 0.95 iter < 5"| B3_IN
    end

    %% ============================================================
    %% PHASE 4: JERRY APPLICATION ANALYSIS (PARALLEL, 5 agents, each with gate)
    %% ============================================================
    subgraph PHASE4["PHASE 4: Jerry Application Analysis (PARALLEL fan-out) — 5 agent gates"]
        direction TB
        style PHASE4 fill:#1a3350,stroke:#4a90d9,color:#ffffff,stroke-width:2px

        P4_A4["<b>ps-analyst-004</b><br/>Skills update analysis<br/><i>Reads: skills/*/SKILL.md</i><br/><i>Data: Jerry codebase + Barrier 3 artifacts</i><br/>TASK-010"]
        P4_A4_GATE{"<b>/adversary C4 Gate</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke ps-analyst-004"}
        P4_A4_OUT["GATED: analysis/skills-analysis.md"]

        P4_A5["<b>ps-analyst-005</b><br/>Agents update analysis<br/><i>Reads: skills/*/agents/*.md</i><br/><i>Data: Jerry codebase + Barrier 3 artifacts</i><br/>TASK-011"]
        P4_A5_GATE{"<b>/adversary C4 Gate</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke ps-analyst-005"}
        P4_A5_OUT["GATED: analysis/agents-analysis.md"]

        P4_A6["<b>ps-analyst-006</b><br/>Rules update analysis<br/><i>Reads: .context/rules/*.md</i><br/><i>Data: Jerry codebase + Barrier 3 artifacts</i><br/><i>NOTE: AE-002 applies (auto-C3+)</i><br/>TASK-012"]
        P4_A6_GATE{"<b>/adversary C4 Gate</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke ps-analyst-006"}
        P4_A6_OUT["GATED: analysis/rules-analysis.md"]

        P4_A7["<b>ps-analyst-007</b><br/>Patterns update analysis<br/><i>Reads: docs/knowledge/*.md,<br/>.context/rules/prompt-quality.md,<br/>.context/rules/prompt-templates.md</i><br/><i>Data: Jerry codebase + Barrier 3 artifacts</i><br/>TASK-013"]
        P4_A7_GATE{"<b>/adversary C4 Gate</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke ps-analyst-007"}
        P4_A7_OUT["GATED: analysis/patterns-analysis.md"]

        P4_A8["<b>ps-analyst-008</b><br/>Templates update analysis<br/><i>Reads: .context/templates/**/*</i><br/><i>Data: Jerry codebase + Barrier 3 artifacts</i><br/>TASK-014"]
        P4_A8_GATE{"<b>/adversary C4 Gate</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke ps-analyst-008"}
        P4_A8_OUT["GATED: analysis/templates-analysis.md"]

        P4_A4 --> P4_A4_GATE
        P4_A4_GATE -->|"PASS"| P4_A4_OUT
        P4_A4_GATE -->|"FAIL iter < 5"| P4_A4

        P4_A5 --> P4_A5_GATE
        P4_A5_GATE -->|"PASS"| P4_A5_OUT
        P4_A5_GATE -->|"FAIL iter < 5"| P4_A5

        P4_A6 --> P4_A6_GATE
        P4_A6_GATE -->|"PASS"| P4_A6_OUT
        P4_A6_GATE -->|"FAIL iter < 5"| P4_A6

        P4_A7 --> P4_A7_GATE
        P4_A7_GATE -->|"PASS"| P4_A7_OUT
        P4_A7_GATE -->|"FAIL iter < 5"| P4_A7

        P4_A8 --> P4_A8_GATE
        P4_A8_GATE -->|"PASS"| P4_A8_OUT
        P4_A8_GATE -->|"FAIL iter < 5"| P4_A8
    end

    B3_OUT --> PHASE4

    P4_A4_OUT -->|"gated skills-analysis.md"| B4_IN
    P4_A5_OUT -->|"gated agents-analysis.md"| B4_IN
    P4_A6_OUT -->|"gated rules-analysis.md"| B4_IN
    P4_A7_OUT -->|"gated patterns-analysis.md"| B4_IN
    P4_A8_OUT -->|"gated templates-analysis.md"| B4_IN

    %% ============================================================
    %% BARRIER 4: APPLICATION CROSS-POLLINATION (on already-gated inputs)
    %% ============================================================
    subgraph BARRIER4["BARRIER 4: Application Cross-Pollination (gated inputs)"]
        direction TB
        style BARRIER4 fill:#5c2d00,stroke:#ff8c00,color:#ffffff,stroke-width:3px

        B4_IN{{"Fan-in: 5 ALREADY GATED analysis outputs"}}
        B4_SYNTH["<b>ps-synthesizer-003</b><br/>Cross-pollinate all 5 gated analyses:<br/>skills, agents, rules, patterns, templates<br/>TASK-015"]
        B4_GATE{"<b>/adversary C4 Gate on Synthesis</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke ps-synthesizer-003<br/><b>Checks:</b><br/>- Cross-domain conflicts identified and resolved<br/>- Recommendations traceable to taxonomy + literature<br/>- Priority ranking justified<br/>- Sequence plan accounts for AE-002 risk"}
        B4_OUT["barrier-4/synthesis.md<br/>+ barrier-4/adversary-gate.md"]

        B4_IN --> B4_SYNTH
        B4_SYNTH --> B4_GATE
        B4_GATE -->|"PASS >= 0.95"| B4_OUT
        B4_GATE -->|"FAIL < 0.95 iter < 5"| B4_SYNTH
    end

    %% ============================================================
    %% PHASE 5: IMPLEMENTATION PLANNING (SEQUENTIAL, 4 ADRs, each with gate)
    %% ============================================================
    subgraph PHASE5["PHASE 5: Implementation Planning (SEQUENTIAL) — 4 agent gates"]
        direction TB
        style PHASE5 fill:#1e3a5f,stroke:#4a90d9,color:#ffffff,stroke-width:2px

        P5_AR2["<b>ps-architect-002</b> — STEP 1<br/>ADR-014-001: How to apply negative<br/>prompting to Jerry skills<br/>Nygard ADR format, options analysis<br/><i>Data: Barrier 4 synthesis +<br/>analysis/skills-analysis.md</i><br/>TASK-016"]
        P5_AR2_GATE{"<b>/adversary C4 Gate</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke ps-architect-002"}
        P5_AR2_OUT["GATED: ADR-014-001"]

        P5_AR3["<b>ps-architect-003</b> — STEP 2<br/>ADR-014-002: How to update Jerry<br/>agent definitions with negative prompting<br/><i>Data: Barrier 4 synthesis +<br/>analysis/agents-analysis.md</i><br/>TASK-016"]
        P5_AR3_GATE{"<b>/adversary C4 Gate</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke ps-architect-003"}
        P5_AR3_OUT["GATED: ADR-014-002"]

        P5_AR4["<b>ps-architect-004</b> — STEP 3<br/>ADR-014-003: How to update Jerry rules<br/>with negative prompting<br/><i>Escalation: AE-002 + AE-003 apply</i><br/><i>Data: Barrier 4 synthesis +<br/>analysis/rules-analysis.md</i><br/>TASK-016"]
        P5_AR4_GATE{"<b>/adversary C4 Gate</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke ps-architect-004"}
        P5_AR4_OUT["GATED: ADR-014-003"]

        P5_AR5["<b>ps-architect-005</b> — STEP 4<br/>ADR-014-004: How to update Jerry<br/>patterns and templates<br/><i>Data: Barrier 4 synthesis +<br/>analysis/patterns-analysis.md +<br/>analysis/templates-analysis.md</i><br/>TASK-016"]
        P5_AR5_GATE{"<b>/adversary C4 Gate</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke ps-architect-005"}
        P5_AR5_OUT["GATED: ADR-014-004"]

        P5_AR2 --> P5_AR2_GATE
        P5_AR2_GATE -->|"PASS"| P5_AR2_OUT
        P5_AR2_GATE -->|"FAIL iter < 5"| P5_AR2
        P5_AR2_OUT --> P5_AR3
        P5_AR3 --> P5_AR3_GATE
        P5_AR3_GATE -->|"PASS"| P5_AR3_OUT
        P5_AR3_GATE -->|"FAIL iter < 5"| P5_AR3
        P5_AR3_OUT --> P5_AR4
        P5_AR4 --> P5_AR4_GATE
        P5_AR4_GATE -->|"PASS"| P5_AR4_OUT
        P5_AR4_GATE -->|"FAIL iter < 5"| P5_AR4
        P5_AR4_OUT --> P5_AR5
        P5_AR5 --> P5_AR5_GATE
        P5_AR5_GATE -->|"PASS"| P5_AR5_OUT
        P5_AR5_GATE -->|"FAIL iter < 5"| P5_AR5
    end

    B4_OUT --> PHASE5

    P5_AR5_OUT -->|"4 gated ADRs"| B5_IN

    %% ============================================================
    %% BARRIER 5: IMPLEMENTATION QUALITY GATE (on already-gated ADRs)
    %% ============================================================
    subgraph BARRIER5["BARRIER 5: Implementation Quality Gate (gated inputs)"]
        direction TB
        style BARRIER5 fill:#5c2d00,stroke:#ff8c00,color:#ffffff,stroke-width:3px

        B5_IN{{"Gate input: 4 ALREADY GATED ADRs<br/>ADR-014-001, ADR-014-002,<br/>ADR-014-003, ADR-014-004"}}
        B5_GATE{"<b>/adversary C4 Gate on Cross-ADR Coherence</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke relevant ps-architect<br/><b>Checks:</b><br/>- All ADRs in Nygard format<br/>- Minimum 2 options considered per ADR<br/>- Decisions traceable to evidence<br/>- Consequences cover positive and negative<br/>- ADR-014-003 includes AE-002 escalation impact"}
        B5_OUT["barrier-5/gate.md"]

        B5_IN --> B5_GATE
        B5_GATE -->|"PASS >= 0.95"| B5_OUT
        B5_GATE -->|"FAIL < 0.95 iter < 5"| B5_IN
    end

    %% ============================================================
    %% PHASE 6: FINAL SYNTHESIS + C4 TOURNAMENT (SEQUENTIAL, each with gate)
    %% ============================================================
    subgraph PHASE6["PHASE 6: Final Synthesis + C4 Tournament (SEQUENTIAL) — 2 agent gates + 1 tournament"]
        direction TB
        style PHASE6 fill:#1e3a5f,stroke:#4a90d9,color:#ffffff,stroke-width:2px

        P6_S4["<b>ps-synthesizer-004</b> — STEP 1<br/>Unified synthesis: all findings from Phases 1-5<br/><i>Input: All barrier synthesis files + all ADRs</i><br/>TASK-018"]
        P6_S4_GATE{"<b>/adversary C4 Gate</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke ps-synthesizer-004"}
        P6_S4_OUT["GATED: synthesis/final-synthesis.md"]

        P6_AR6["<b>ps-architect-006</b> — STEP 2<br/>Final implementation roadmap with priorities:<br/>phased plan — what to change first, second, third<br/><i>Input: GATED synthesis/final-synthesis.md</i><br/>TASK-018"]
        P6_AR6_GATE{"<b>/adversary C4 Gate</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iter<br/>FAIL: re-invoke ps-architect-006"}
        P6_AR6_OUT["GATED: synthesis/implementation-roadmap.md"]

        P6_S4 --> P6_S4_GATE
        P6_S4_GATE -->|"PASS >= 0.95"| P6_S4_OUT
        P6_S4_GATE -->|"FAIL < 0.95 iter < 5"| P6_S4
        P6_S4_OUT --> P6_AR6
        P6_AR6 --> P6_AR6_GATE
        P6_AR6_GATE -->|"PASS >= 0.95"| P6_AR6_OUT
        P6_AR6_GATE -->|"FAIL < 0.95 iter < 5"| P6_AR6
    end

    B5_OUT --> PHASE6

    P6_AR6_OUT -->|"2 gated synthesis artifacts"| TOURNAMENT_IN

    %% ============================================================
    %% C4 TOURNAMENT (Final quality gate — ALL 10 strategies)
    %% ============================================================
    subgraph TOURNAMENT["C4 TOURNAMENT: All 10 Adversarial Strategies (3-agent pipeline)"]
        direction TB
        style TOURNAMENT fill:#6b4c00,stroke:#ffd700,color:#ffffff,stroke-width:4px

        TOURNAMENT_IN{{"Tournament input:<br/>GATED synthesis/final-synthesis.md +<br/>GATED synthesis/implementation-roadmap.md"}}

        T_STRATS["<b>/adversary C4 TOURNAMENT</b><br/>adv-selector -> adv-executor -> adv-scorer<br/>Score >= 0.95 | Max 5 iterations<br/>FAIL: re-invoke ps-synthesizer-004 / ps-architect-006<br/>TASK-019<br/><br/><b>All 10 Strategies Executed:</b><br/>S-001 Red Team Analysis<br/>S-002 Devil s Advocate<br/>S-003 Steelman Technique<br/>S-004 Pre-Mortem Analysis<br/>S-007 Constitutional AI Critique<br/>S-010 Self-Refine<br/>S-011 Chain-of-Verification<br/>S-012 FMEA<br/>S-013 Inversion Technique<br/>S-014 LLM-as-Judge"]

        T_OUT["adversary/c4-tournament/<br/>Individual strategy reports +<br/>tournament-summary.md"]

        TOURNAMENT_IN --> T_STRATS
        T_STRATS -->|"PASS >= 0.95"| T_OUT
        T_STRATS -->|"FAIL < 0.95 iter < 5"| TOURNAMENT_IN
    end

    %% ============================================================
    %% WORKFLOW COMPLETE
    %% ============================================================
    T_OUT --> DONE

    DONE(["WORKFLOW COMPLETE<br/>All 6 phases passed<br/>All 17 agent gates passed<br/>All 5 barrier gates passed<br/>C4 tournament passed<br/>23 total quality gates >= 0.95"])
    style DONE fill:#006400,stroke:#00ff00,color:#ffffff,stroke-width:3px

    %% ============================================================
    %% LEGEND / METRICS SUMMARY
    %% ============================================================
    subgraph LEGEND["Legend and Metrics"]
        direction LR
        style LEGEND fill:#2a2a2a,stroke:#888888,color:#ffffff,stroke-width:1px

        L_AGENT["Agent Node<br/>(rounded rectangle)"]
        L_GATE{"Quality Gate<br/>(diamond)"}
        L_GATED["GATED Output<br/>(passed adversary gate)"]
        L_FANIN{{"Fan-in / Gate Input<br/>(hexagon)"}}
        L_METRICS["<b>Workflow Metrics:</b><br/>Phases: 6 | Creator Agents: 17<br/>Agent Quality Gates: 17<br/>Barrier Quality Gates: 5<br/>Final Tournament: 1 (all 10 strategies)<br/>Total Quality Gates: 23<br/>Adversary Pipeline: adv-selector, adv-executor, adv-scorer<br/>Min Sources: 50+ unique<br/>Quality Threshold: >= 0.95 everywhere<br/>Max Iterations per Gate: 5<br/>Feedback: re-invoke creator agent NEVER main context<br/>Data Sources: WebSearch, WebFetch, Context7<br/>Context7 Libraries: Anthropic, OpenAI,<br/>LangChain, LlamaIndex, DSPy"]
    end
```

---

### Pipeline Definitions

| Pipeline | Alias | Skill Source | Purpose |
|----------|-------|-------------|---------|
| Research & Analysis | `ps` | problem-solving | Research, analysis, synthesis, architecture, quality review |

**Note:** This workflow uses a single pipeline with per-agent `/adversary` quality gates on EVERY creator output, plus `/adversary` quality gates on every barrier synthesis. The adversary uses a 3-agent pipeline (adv-selector -> adv-executor -> adv-scorer) at every gate. Barriers receive already-gated inputs. Feedback is addressed by re-invoking the creator agent in agent context (never in the main context window).

### Phase Summary Table

| Phase | Pattern | Creator Agents | Agent Gates | Data Sources | Barrier Gate |
|-------|---------|--------|-------------|-------------|-------------|
| Phase 1: Literature Research | Fan-Out (3 parallel) | ps-researcher-001, 002, 003 | 3 per-agent C4 gates | WebSearch, WebFetch, Context7 | Barrier 1 synthesis gate |
| Barrier 1 | Fan-In + Adversary | ps-synthesizer-001 | (synthesis gated) | 3 gated research outputs | >= 0.95, 5 iter |
| Phase 2: Evidence Analysis | Fan-Out (2 parallel) | ps-analyst-001, 002 | 2 per-agent C4 gates | Barrier 1 synthesis | Barrier 2 synthesis gate |
| Barrier 2 | Fan-In + Adversary | ps-synthesizer-002 | (synthesis gated) | 2 gated analysis outputs | >= 0.95, 5 iter |
| Phase 3: Taxonomy | Sequential (2 steps) | ps-analyst-003, ps-architect-001 | 2 per-agent C4 gates | Barrier 2 synthesis | Barrier 3 coherence gate |
| Barrier 3 | Adversary (coherence) | -- | -- | 2 gated artifacts | >= 0.95, 5 iter |
| Phase 4: Jerry Application | Fan-Out (5 parallel) | ps-analyst-004 through 008 | 5 per-agent C4 gates | Jerry codebase + Barrier 3 | Barrier 4 synthesis gate |
| Barrier 4 | Fan-In + Adversary | ps-synthesizer-003 | (synthesis gated) | 5 gated analysis outputs | >= 0.95, 5 iter |
| Phase 5: Implementation Planning | Sequential (4 steps) | ps-architect-002 through 005 | 4 per-agent C4 gates | Barrier 4 synthesis | Barrier 5 coherence gate |
| Barrier 5 | Adversary (coherence) | -- | -- | 4 gated ADRs | >= 0.95, 5 iter |
| Phase 6: Final Synthesis | Sequential (3 steps) | ps-synthesizer-004, ps-architect-006 | 2 per-agent C4 gates | All prior artifacts | C4 Tournament |
| **Totals** | | **17 creator agents** | **17 agent gates** | | **5 barrier gates + 1 tournament = 23 total** |

### Sync Barriers

**Key change from previous plan:** Barriers now receive ALREADY quality-gated inputs. Each barrier's gate validates cross-artifact coherence on the synthesis output, not the individual inputs (those are already gated at the agent level).

| Barrier | Trigger Condition | Input Quality | Gate Type | Threshold | Max Iterations | Adversary Pipeline | Feedback Target |
|---------|------------------|---------------|-----------|-----------|----------------|-------------------|-----------------|
| Barrier 1 | 3 research reports gated and present | All 3 inputs passed per-agent C4 gate | /adversary C4 on synthesis | >= 0.95 | 5 | adv-selector -> adv-executor -> adv-scorer | Re-invoke ps-synthesizer-001 |
| Barrier 2 | 2 analysis reports gated and present | Both inputs passed per-agent C4 gate | /adversary C4 on synthesis | >= 0.95 | 5 | adv-selector -> adv-executor -> adv-scorer | Re-invoke ps-synthesizer-002 |
| Barrier 3 | taxonomy.md + pattern-catalog.md gated and present | Both inputs passed per-agent C4 gate | /adversary C4 on cross-artifact coherence | >= 0.95 | 5 | adv-selector -> adv-executor -> adv-scorer | Re-invoke ps-analyst-003 / ps-architect-001 |
| Barrier 4 | 5 application analyses gated and present | All 5 inputs passed per-agent C4 gate | /adversary C4 on synthesis | >= 0.95 | 5 | adv-selector -> adv-executor -> adv-scorer | Re-invoke ps-synthesizer-003 |
| Barrier 5 | 4 ADRs gated and present | All 4 inputs passed per-agent C4 gate | /adversary C4 on cross-ADR coherence | >= 0.95 | 5 | adv-selector -> adv-executor -> adv-scorer | Re-invoke relevant ps-architect |
| Barrier 6 (final) | final-synthesis.md + roadmap.md gated and present | Both inputs passed per-agent C4 gate | C4 Tournament (all 10 strategies) | >= 0.95 | 5 | adv-selector -> adv-executor -> adv-scorer | Re-invoke ps-synthesizer-004 / ps-architect-006 |

---

## L2: Implementation Details

### State Schema (ORCHESTRATION.yaml)

See `ORCHESTRATION.yaml` in this directory for the machine-readable state.

### Dynamic Path Configuration

**Base path scheme:**

```
projects/PROJ-014-negative-prompting-research/
├── research/                          # Phase 1 research outputs
│   ├── academic-survey.md             # ps-researcher-001
│   ├── industry-survey.md             # ps-researcher-002
│   └── context7-survey.md             # ps-researcher-003
├── analysis/                          # Phase 2, 3, 4 outputs
│   ├── claim-validation.md            # ps-analyst-001
│   ├── comparative.md                 # ps-analyst-002
│   ├── taxonomy.md                    # ps-analyst-003
│   ├── skills-analysis.md             # ps-analyst-004
│   ├── agents-analysis.md             # ps-analyst-005
│   ├── rules-analysis.md              # ps-analyst-006
│   ├── patterns-analysis.md           # ps-analyst-007
│   └── templates-analysis.md          # ps-analyst-008
├── decisions/                         # Phase 3, 5 outputs
│   ├── pattern-catalog.md             # ps-architect-001
│   ├── ADR-014-001-skills-negative-prompting.md        # ps-architect-002
│   ├── ADR-014-002-agents-negative-prompting.md        # ps-architect-003
│   ├── ADR-014-003-rules-negative-prompting.md         # ps-architect-004
│   └── ADR-014-004-patterns-templates-negative-prompting.md  # ps-architect-005
├── synthesis/                         # Phase 6 outputs
│   ├── final-synthesis.md             # ps-synthesizer-004
│   └── implementation-roadmap.md      # ps-architect-006
└── orchestration/
    └── neg-prompting-20260227-001/    # State and quality gate artifacts
        ├── ORCHESTRATION.yaml         # Machine-readable state
        ├── ORCHESTRATION_PLAN.md      # This file
        ├── barrier-1/
        │   └── synthesis.md           # Barrier 1 cross-pollination
        ├── barrier-2/
        │   └── synthesis.md           # Barrier 2 cross-pollination
        ├── barrier-3/
        │   └── gate.md                # Barrier 3 quality gate report
        ├── barrier-4/
        │   └── synthesis.md           # Barrier 4 cross-pollination
        ├── barrier-5/
        │   └── gate.md                # Barrier 5 quality gate report
        ├── agent-gates/               # Per-agent adversary gate reports
        │   ├── ps-researcher-001-gate.md
        │   ├── ps-researcher-002-gate.md
        │   ├── ps-researcher-003-gate.md
        │   ├── ps-analyst-001-gate.md
        │   ├── ps-analyst-002-gate.md
        │   ├── ps-analyst-003-gate.md
        │   ├── ps-analyst-004-gate.md
        │   ├── ps-analyst-005-gate.md
        │   ├── ps-analyst-006-gate.md
        │   ├── ps-analyst-007-gate.md
        │   ├── ps-analyst-008-gate.md
        │   ├── ps-architect-001-gate.md
        │   ├── ps-architect-002-gate.md
        │   ├── ps-architect-003-gate.md
        │   ├── ps-architect-004-gate.md
        │   ├── ps-architect-005-gate.md
        │   ├── ps-architect-006-gate.md
        │   ├── ps-synthesizer-001-gate.md  # Barrier 1 synthesis gate
        │   ├── ps-synthesizer-002-gate.md  # Barrier 2 synthesis gate
        │   ├── ps-synthesizer-003-gate.md  # Barrier 4 synthesis gate
        │   └── ps-synthesizer-004-gate.md  # Phase 6 synthesis gate
        └── adversary/
            └── c4-tournament/         # Phase 6 tournament artifacts
```

### Recovery Strategies

| Failure Mode | Recovery Action |
|-------------|----------------|
| Researcher produces < 25 sources | Re-run researcher with explicit source count instruction; add WebFetch for specific papers |
| Per-agent adversary gate fails iteration 5 | STOP that agent. Escalate to user with: current best score, specific gaps from adv-scorer, full adversary gate report. User decides: (a) accept current quality, (b) provide guidance and retry, (c) replace agent approach |
| Barrier synthesis gate fails iteration 5 | Escalate to user with: synthesis score, specific cross-artifact issues identified by adv-executor, list of which upstream gated outputs may need revision. User decides: (a) revise synthesis approach, (b) re-run specific upstream agents with new guidance |
| Context window exhaustion mid-phase | Checkpoint current state; resume from last completed agent in phase. Per-agent gates already completed do NOT need to be re-run |
| Context7 returns no results | Fall back to WebSearch + note "Context7 no coverage" in output |
| Analyst cannot find Jerry codebase files | Use Glob to enumerate files; read in batches per CB-05 (500-line limit) |
| Phase 4 analysis contradicts Phase 3 taxonomy | Document contradiction; flag for Phase 6 synthesizer to resolve |
| Adversary feedback cannot be addressed in agent context | NEVER address in main context. Re-invoke the creator agent with the specific adversary findings as input. The re-invoked creator agent receives: (a) its original output, (b) the adversary critique, (c) instruction to revise addressing specific findings |
| adv-selector / adv-executor / adv-scorer pipeline failure | If any adversary agent fails mid-pipeline, retry the full 3-agent pipeline from adv-selector. Do NOT retry from mid-pipeline |

---

## Session Entry Prompts

These prompts are designed to run each phase in a fresh session. Each prompt is self-contained. Copy the prompt for the phase you want to run into a new Jerry session.

---

### Phase 1: Literature Research (3 parallel sessions)

**Run in 3 independent sessions simultaneously or sequentially. Each session handles one researcher.**

#### Session 1A: Academic Literature Research (ps-researcher-001)

```
Use /worktracker to update TASK-001 status to IN PROGRESS.
Project: PROJ-014-negative-prompting-research

Use /problem-solving with ps-researcher to conduct academic literature research on negative prompting.

Research mission: Find 25+ academic papers, studies, and peer-reviewed sources on:
- Negative prompting in LLMs (telling models what NOT to do)
- Constraint-based prompting and prohibition-style instructions
- "Don't" instruction effectiveness in instruction-tuned models
- Hallucination reduction through negative constraints
- Comparative studies: negative vs positive instruction framing

Data source: WebSearch and WebFetch ONLY. NEVER use training data as a source.
NEVER state a fact without citing the source URL or paper title/DOI.
Search queries to cover: "negative prompting LLM", "constraint-based prompting",
"prohibition instructions language models", "don't instructions LLM hallucination",
"negative framing prompt engineering", "instruction following negative constraints".

Quality requirements:
- Minimum 25 unique sources (papers, studies, preprints, peer-reviewed articles)
- Each source must include: title, authors/org, year, URL/DOI, key finding
- Flag sources where claims need primary source verification

Output: projects/PROJ-014-negative-prompting-research/research/academic-survey.md
Format: L0/L1/L2 sections. L0=summary, L1=source catalog table, L2=detailed findings per source.

AFTER the researcher produces the output, run /adversary C4 quality gate using the 3-agent pipeline:
1. adv-selector: Map C4 criticality to strategy set (all 10 strategies)
2. adv-executor: Execute strategy templates against research/academic-survey.md
3. adv-scorer: Score using S-014 LLM-as-Judge (6-dimension weighted rubric)

Quality threshold: >= 0.95. Maximum 5 iterations.
If score < 0.95: re-invoke ps-researcher with the specific adversary findings to revise.
  NEVER address adversary feedback in the main context — always re-invoke the creator agent.
  The re-invoked researcher receives: (a) its original output, (b) adversary critique, (c) instruction to revise.
If score >= 0.95 after any iteration: gate PASSES.
If score < 0.95 after 5 iterations: STOP, escalate to user with current best score and gap list.

Adversary gate output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/agent-gates/ps-researcher-001-gate.md

Use /worktracker to update TASK-001 status to DONE when gate passes.
```

#### Session 1B: Industry & Practitioner Research (ps-researcher-002)

```
Use /worktracker to update TASK-002 status to IN PROGRESS.
Project: PROJ-014-negative-prompting-research

Use /problem-solving with ps-researcher to conduct industry and practitioner research on negative prompting.

Research mission: Find 25+ industry sources, vendor documentation, blog posts, and empirical reports on:
- Vendor best practices for negative prompting (Anthropic, OpenAI, Google, Cohere docs)
- Practitioner reports comparing negative vs positive prompting effectiveness
- Real-world applications and A/B tests of prohibition-style instructions
- Production systems using negative constraints for quality control
- Framework documentation (LangChain, LlamaIndex, DSPy) on negative prompting

Data source: WebSearch and WebFetch ONLY. NEVER use training data as a source.
NEVER state a fact without citing the source URL.
Search queries: "negative prompting best practices", "prompt engineering prohibitions",
"negative instructions production LLM", vendor documentation searches for each major provider.

Quality requirements:
- Minimum 25 unique sources (vendor docs, blog posts, case studies, tutorials)
- Each source: title, org, year, URL, key finding
- Distinguish: vendor recommendation vs empirical evidence vs anecdote

Output: projects/PROJ-014-negative-prompting-research/research/industry-survey.md
Format: L0/L1/L2 sections.

AFTER the researcher produces the output, run /adversary C4 quality gate using the 3-agent pipeline:
1. adv-selector: Map C4 criticality to strategy set (all 10 strategies)
2. adv-executor: Execute strategy templates against research/industry-survey.md
3. adv-scorer: Score using S-014 LLM-as-Judge (6-dimension weighted rubric)

Quality threshold: >= 0.95. Maximum 5 iterations.
If score < 0.95: re-invoke ps-researcher with the specific adversary findings to revise.
  NEVER address adversary feedback in the main context — always re-invoke the creator agent.
If score >= 0.95 after any iteration: gate PASSES.
If score < 0.95 after 5 iterations: STOP, escalate to user.

Adversary gate output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/agent-gates/ps-researcher-002-gate.md

Use /worktracker to update TASK-002 status to DONE when gate passes.
```

#### Session 1C: Context7 Library Documentation Research (ps-researcher-003)

```
Use /worktracker to update TASK-003 status to IN PROGRESS.
Project: PROJ-014-negative-prompting-research

Use /problem-solving with ps-researcher to research negative prompting in library documentation via Context7.

Research mission: Use Context7 (mcp__context7__resolve-library-id then mcp__context7__query-docs)
to find documented negative prompting patterns in:
1. Anthropic Claude documentation
2. OpenAI documentation
3. LangChain framework documentation
4. LlamaIndex documentation
5. DSPy documentation
6. Prompt engineering guides (DSPY, guidance, outlines)

For each library:
1. Call resolve-library-id to find the library
2. Query for: "negative prompting", "what not to do instructions", "prohibition constraints",
   "hallucination reduction instructions", "avoid instructions"
3. Extract all documented patterns, examples, and recommendations

If Context7 returns no results for a library, fall back to WebSearch and note "Context7 no coverage".
NEVER state a fact without the Context7 source (library + query) or WebSearch URL.

Quality requirements:
- Cover all 6 library categories above
- Document the exact query used for each Context7 call
- Include code examples where available
- Note which frameworks have explicit negative prompting guidance

Output: projects/PROJ-014-negative-prompting-research/research/context7-survey.md
Format: L0/L1/L2 sections.

AFTER the researcher produces the output, run /adversary C4 quality gate using the 3-agent pipeline:
1. adv-selector: Map C4 criticality to strategy set (all 10 strategies)
2. adv-executor: Execute strategy templates against research/context7-survey.md
3. adv-scorer: Score using S-014 LLM-as-Judge (6-dimension weighted rubric)

Quality threshold: >= 0.95. Maximum 5 iterations.
If score < 0.95: re-invoke ps-researcher with the specific adversary findings to revise.
  NEVER address adversary feedback in the main context — always re-invoke the creator agent.
If score >= 0.95 after any iteration: gate PASSES.
If score < 0.95 after 5 iterations: STOP, escalate to user.

Adversary gate output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/agent-gates/ps-researcher-003-gate.md

Use /worktracker to update TASK-003 status to DONE when gate passes.
```

---

### Barrier 1: Research Cross-Pollination + /adversary Quality Gate

**Prerequisites:** TASK-001, TASK-002, TASK-003 all DONE. All three research files present AND all three per-agent adversary gates PASSED (>= 0.95).

```
Use /worktracker to update TASK-004 status to IN PROGRESS.
Project: PROJ-014-negative-prompting-research

Verify all 3 QUALITY-GATED research files exist:
- projects/PROJ-014-negative-prompting-research/research/academic-survey.md (gated by ps-researcher-001 adversary gate)
- projects/PROJ-014-negative-prompting-research/research/industry-survey.md (gated by ps-researcher-002 adversary gate)
- projects/PROJ-014-negative-prompting-research/research/context7-survey.md (gated by ps-researcher-003 adversary gate)
If any file is missing or any per-agent gate did not pass, STOP and report the blocker.

Use /problem-solving with ps-synthesizer to cross-pollinate the 3 ALREADY GATED research outputs.

Synthesis tasks:
1. Merge source catalogs — deduplicate overlapping sources across all 3 surveys
2. Identify agreements: where academic, industry, and library docs align
3. Identify gaps: claims made in one survey with no corroboration in others
4. Identify conflicts: contradictory findings across surveys
5. Count total unique sources (must be >= 50)
6. Flag any claims without citation evidence

Output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/barrier-1/synthesis.md

AFTER the synthesizer produces the output, run /adversary C4 quality gate on the synthesis using the 3-agent pipeline:
1. adv-selector: Map C4 criticality to strategy set (all 10 strategies)
2. adv-executor: Execute strategy templates against barrier-1/synthesis.md
3. adv-scorer: Score using S-014 LLM-as-Judge (6-dimension weighted rubric)

Quality threshold: >= 0.95. Maximum 5 iterations.
Required checks:
- Minimum 50 unique sources cited in the synthesis
- No unsourced claims (every assertion has a citation)
- No training-data-only assertions (all from WebSearch or Context7)
- Source quality is appropriate (peer-reviewed or authoritative vendor docs)

If score < 0.95: re-invoke ps-synthesizer with the specific adversary findings to revise.
  NEVER address adversary feedback in the main context — always re-invoke the creator agent.
If score >= 0.95 after any iteration: gate PASSES. Proceed.
If score < 0.95 after 5 iterations: STOP, escalate to user with current best score and gap list.

/adversary gate output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/barrier-1/adversary-gate.md

Use /worktracker to update TASK-004 status to DONE when gate passes.
```

---

### Phase 2: Evidence Analysis (2 parallel sessions)

**Prerequisites:** Barrier 1 gate PASSED.

#### Session 2A: Claim Validation (ps-analyst-001)

```
Use /worktracker to update TASK-005 status to IN PROGRESS.
Project: PROJ-014-negative-prompting-research

Load context:
- projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/barrier-1/synthesis.md

Use /problem-solving with ps-analyst to validate the 60% hallucination reduction claim.

Analysis mission:
1. Locate the specific source(s) that make the "60% hallucination reduction" claim
2. Trace to primary source: who conducted the study, what methodology, what conditions
3. Assess methodology quality: was it a controlled experiment? what was the baseline?
4. Identify conditions: does the reduction apply universally or only in specific contexts?
5. Identify limitations: what does the study NOT cover?
6. Find contradictory evidence: are there studies showing smaller or no reduction?
7. Synthesize: is the 60% claim supported, qualified, refuted, or unsubstantiated?

NEVER state a fact without citing source. Use WebSearch and WebFetch to access primary sources
identified in Barrier 1 synthesis. NEVER rely on training data for quantitative claims.

Output: projects/PROJ-014-negative-prompting-research/analysis/claim-validation.md
Include: claim assessment verdict (supported/qualified/refuted/unsubstantiated),
evidence chain, methodology critique, conditions and limitations, recommendation.

AFTER the analyst produces the output, run /adversary C4 quality gate using the 3-agent pipeline:
1. adv-selector: Map C4 criticality to strategy set (all 10 strategies)
2. adv-executor: Execute strategy templates against analysis/claim-validation.md
3. adv-scorer: Score using S-014 LLM-as-Judge (6-dimension weighted rubric)

Quality threshold: >= 0.95. Maximum 5 iterations.
If score < 0.95: re-invoke ps-analyst with the specific adversary findings to revise.
  NEVER address adversary feedback in the main context — always re-invoke the creator agent.
If score >= 0.95 after any iteration: gate PASSES.
If score < 0.95 after 5 iterations: STOP, escalate to user.

Adversary gate output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/agent-gates/ps-analyst-001-gate.md

Use /worktracker to update TASK-005 status to DONE when gate passes.
```

#### Session 2B: Comparative Effectiveness Analysis (ps-analyst-002)

```
Use /worktracker to update TASK-006 status to IN PROGRESS.
Project: PROJ-014-negative-prompting-research

Load context:
- projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/barrier-1/synthesis.md

Use /problem-solving with ps-analyst to conduct comparative effectiveness analysis.

Analysis mission: Compare positive vs negative prompting across 5 dimensions:
1. Accuracy: Does negative prompting produce more accurate outputs?
2. Compliance: Do models follow negative constraints more reliably than positive directions?
3. Hallucination: Does negative prompting reduce hallucination more than positive prompting?
4. Instruction-following: Are prohibitions ("never X") obeyed more strictly than directives ("do X")?
5. Creativity: Does negative prompting constrain or enable creative outputs differently?

For each dimension:
- What does the evidence show? (cite sources from Barrier 1 synthesis)
- What are the conditions under which each approach excels?
- What are the failure modes of each approach?
- Use WebSearch/WebFetch to access primary sources where needed

NEVER state a fact without citing source. NEVER use training data for comparative claims.

Output: projects/PROJ-014-negative-prompting-research/analysis/comparative.md
Include: dimension-by-dimension comparison table, synthesized verdict per dimension,
overall recommendation, gaps and open questions.

AFTER the analyst produces the output, run /adversary C4 quality gate using the 3-agent pipeline:
1. adv-selector: Map C4 criticality to strategy set (all 10 strategies)
2. adv-executor: Execute strategy templates against analysis/comparative.md
3. adv-scorer: Score using S-014 LLM-as-Judge (6-dimension weighted rubric)

Quality threshold: >= 0.95. Maximum 5 iterations.
If score < 0.95: re-invoke ps-analyst with the specific adversary findings to revise.
  NEVER address adversary feedback in the main context — always re-invoke the creator agent.
If score >= 0.95 after any iteration: gate PASSES.
If score < 0.95 after 5 iterations: STOP, escalate to user.

Adversary gate output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/agent-gates/ps-analyst-002-gate.md

Use /worktracker to update TASK-006 status to DONE when gate passes.
```

---

### Barrier 2: Analysis Cross-Pollination + /adversary Quality Gate

**Prerequisites:** TASK-005, TASK-006 both DONE. Both per-agent adversary gates PASSED (>= 0.95).

```
Use /worktracker to update TASK-007 status to IN PROGRESS.
Project: PROJ-014-negative-prompting-research

Load context:
- projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/barrier-1/synthesis.md
- projects/PROJ-014-negative-prompting-research/analysis/claim-validation.md (gated by ps-analyst-001 adversary gate)
- projects/PROJ-014-negative-prompting-research/analysis/comparative.md (gated by ps-analyst-002 adversary gate)

Use /problem-solving with ps-synthesizer to cross-pollinate the 2 ALREADY GATED analysis outputs.

Synthesis tasks:
1. Align claim validation verdict with comparative effectiveness findings
2. Identify any contradictions between the two analyses
3. Consolidate: what is now established with high confidence?
4. Consolidate: what remains uncertain or context-dependent?
5. Summarize: what is the evidence-based answer to the core hypothesis?

Output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/barrier-2/synthesis.md

AFTER the synthesizer produces the output, run /adversary C4 quality gate using the 3-agent pipeline:
1. adv-selector: Map C4 criticality to strategy set (all 10 strategies)
2. adv-executor: Execute strategy templates against barrier-2/synthesis.md
3. adv-scorer: Score using S-014 LLM-as-Judge (6-dimension weighted rubric)

Quality threshold: >= 0.95. Maximum 5 iterations.
Required checks:
- All claims traced to primary sources
- Claim validation includes methodology critique
- Comparative analysis covers all 5 dimensions
- Contradictions explicitly resolved or documented

If score < 0.95: re-invoke ps-synthesizer with the specific adversary findings to revise.
  NEVER address adversary feedback in the main context — always re-invoke the creator agent.
If score >= 0.95 after any iteration: gate PASSES.
If score < 0.95 after 5 iterations: STOP, escalate to user.

/adversary gate output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/barrier-2/adversary-gate.md

Use /worktracker to update TASK-007 status to DONE when gate passes.
```

---

### Phase 3: Negative Prompting Taxonomy (sequential, single session)

**Prerequisites:** Barrier 2 gate PASSED.

```
Use /worktracker to update TASK-008 status to IN PROGRESS.
Project: PROJ-014-negative-prompting-research

Load context:
- projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/barrier-2/synthesis.md
- projects/PROJ-014-negative-prompting-research/analysis/claim-validation.md
- projects/PROJ-014-negative-prompting-research/analysis/comparative.md

STEP 1: Use /problem-solving with ps-analyst to build a taxonomy of negative prompting patterns.

Taxonomy mission:
1. Identify distinct types of negative prompting from the literature
   Examples: categorical prohibitions, output format prohibitions, scope limitations,
   tone prohibitions, factual boundary setting, persona constraints, process prohibitions
2. For each type: when does it work best? when does it fail? what is the evidence basis?
3. Identify anti-patterns: negative prompts that backfire or reduce performance
4. Map to positive-prompting equivalents: for each negative pattern, what is the positive analog?
5. Rate each pattern by evidence strength: strong evidence, moderate evidence, anecdotal only

Output: projects/PROJ-014-negative-prompting-research/analysis/taxonomy.md
Format: taxonomy table (pattern type / description / when it works / when it fails / evidence strength)
plus detailed sections per pattern type.

AFTER ps-analyst-003 produces taxonomy.md, run /adversary C4 quality gate using the 3-agent pipeline:
1. adv-selector: Map C4 criticality to strategy set (all 10 strategies)
2. adv-executor: Execute strategy templates against analysis/taxonomy.md
3. adv-scorer: Score using S-014 LLM-as-Judge (6-dimension weighted rubric)

Quality threshold: >= 0.95. Maximum 5 iterations.
If score < 0.95: re-invoke ps-analyst-003 with the specific adversary findings to revise.
  NEVER address adversary feedback in the main context — always re-invoke the creator agent.
If score >= 0.95: gate PASSES, proceed to STEP 2.
If score < 0.95 after 5 iterations: STOP, escalate to user.

Adversary gate output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/agent-gates/ps-analyst-003-gate.md

STEP 2: Use /problem-solving with ps-architect to design a negative prompting pattern catalog for Jerry.

Catalog mission:
1. Map each taxonomy pattern to Jerry's constraint language (HARD/MEDIUM/SOFT tiers)
2. Show how Jerry's existing positive directives could be rewritten as negative constraints
3. Design a template for negative-constraint rule files
4. Design a template for negative-constraint agent guardrails
5. Propose naming conventions for negative constraints (e.g., NEVER- prefix for HARD)

Input: GATED analysis/taxonomy.md from STEP 1
Output: decisions/pattern-catalog.md

AFTER ps-architect-001 produces pattern-catalog.md, run /adversary C4 quality gate using the 3-agent pipeline:
1. adv-selector: Map C4 criticality to strategy set (all 10 strategies)
2. adv-executor: Execute strategy templates against decisions/pattern-catalog.md
3. adv-scorer: Score using S-014 LLM-as-Judge (6-dimension weighted rubric)

Quality threshold: >= 0.95. Maximum 5 iterations.
If score < 0.95: re-invoke ps-architect-001 with the specific adversary findings to revise.
  NEVER address adversary feedback in the main context — always re-invoke the creator agent.
If score >= 0.95: gate PASSES.
If score < 0.95 after 5 iterations: STOP, escalate to user.

Adversary gate output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/agent-gates/ps-architect-001-gate.md

Use /worktracker to update TASK-008 status to DONE when both gates pass.
```

---

### Barrier 3: Taxonomy Quality Gate

**Prerequisites:** TASK-008 DONE. Both taxonomy.md and pattern-catalog.md present AND both per-agent adversary gates PASSED (>= 0.95).

```
Use /worktracker to update TASK-009 status to IN PROGRESS.
Project: PROJ-014-negative-prompting-research

Load ALREADY QUALITY-GATED artifacts:
- projects/PROJ-014-negative-prompting-research/analysis/taxonomy.md (gated by ps-analyst-003 adversary gate)
- projects/PROJ-014-negative-prompting-research/decisions/pattern-catalog.md (gated by ps-architect-001 adversary gate)

Run /adversary C4 quality gate on CROSS-ARTIFACT COHERENCE using the 3-agent pipeline:
1. adv-selector: Map C4 criticality to strategy set (all 10 strategies)
2. adv-executor: Execute strategy templates against both gated artifacts together
3. adv-scorer: Score using S-014 LLM-as-Judge (6-dimension weighted rubric)

Criticality: C4. Threshold: >= 0.95. Maximum 5 iterations.

Gate requirements (cross-artifact coherence):
- Taxonomy covers all pattern types evidenced in the research (cross-check against Barrier 2 synthesis)
- Each taxonomy pattern has explicit evidence basis (no training-data-only patterns)
- Pattern catalog is actionable for Jerry (maps to real Jerry artifacts)
- Pattern catalog templates are concrete enough to guide implementation
- Anti-patterns section is present and evidence-based

If score < 0.95: re-invoke ps-analyst-003 and/or ps-architect-001 with the specific adversary findings to revise.
  NEVER address adversary feedback in the main context — always re-invoke the creator agent.
If score >= 0.95: gate PASSES.
If score < 0.95 after 5 iterations: STOP, escalate to user.

/adversary gate output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/barrier-3/gate.md

Use /worktracker to update TASK-009 status to DONE when gate passes.
```

---

### Phase 4: Jerry Application Analysis (5 parallel sessions)

**Prerequisites:** Barrier 3 gate PASSED.

**Common context for all Phase 4 sessions:**
All analysts must load: `analysis/taxonomy.md`, `decisions/pattern-catalog.md`, and `orchestration/neg-prompting-20260227-001/barrier-2/synthesis.md` before beginning.

#### Session 4A: Skills Update Analysis (ps-analyst-004)

```
Use /worktracker to update TASK-010 status to IN PROGRESS.
Project: PROJ-014-negative-prompting-research

Load context:
- projects/PROJ-014-negative-prompting-research/analysis/taxonomy.md
- projects/PROJ-014-negative-prompting-research/decisions/pattern-catalog.md

Use /problem-solving with ps-analyst to analyze Jerry skills for negative prompting opportunities.

Analysis mission:
1. Use Glob to find all skill definition files: skills/*/SKILL.md
2. Read each SKILL.md file
3. For each skill: identify all positive directives that could be rewritten as negative constraints
4. Apply the pattern catalog to classify each opportunity by taxonomy type
5. Rate each opportunity: high / medium / low impact on skill quality
6. Identify any skills where negative prompting would be harmful (note why)

NEVER make up findings — base all analysis on actual file content read.
Read files in batches (max 500 lines per read per CB-05).

Output: projects/PROJ-014-negative-prompting-research/analysis/skills-analysis.md
Format: table of opportunities (skill / directive / proposed negative form / taxonomy type / impact)
plus recommendations section.

AFTER the analyst produces the output, run /adversary C4 quality gate using the 3-agent pipeline:
1. adv-selector: Map C4 criticality to strategy set (all 10 strategies)
2. adv-executor: Execute strategy templates against analysis/skills-analysis.md
3. adv-scorer: Score using S-014 LLM-as-Judge (6-dimension weighted rubric)

Quality threshold: >= 0.95. Maximum 5 iterations.
If score < 0.95: re-invoke ps-analyst-004 with the specific adversary findings to revise.
  NEVER address adversary feedback in the main context — always re-invoke the creator agent.
If score >= 0.95: gate PASSES.
If score < 0.95 after 5 iterations: STOP, escalate to user.

Adversary gate output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/agent-gates/ps-analyst-004-gate.md

Use /worktracker to update TASK-010 status to DONE when gate passes.
```

#### Session 4B: Agents Update Analysis (ps-analyst-005)

```
Use /worktracker to update TASK-011 status to IN PROGRESS.
Project: PROJ-014-negative-prompting-research

Load context:
- projects/PROJ-014-negative-prompting-research/analysis/taxonomy.md
- projects/PROJ-014-negative-prompting-research/decisions/pattern-catalog.md

Use /problem-solving with ps-analyst to analyze Jerry agent definitions for negative prompting opportunities.

Analysis mission:
1. Use Glob to find all agent definition files: skills/*/agents/*.md
2. Read each agent definition
3. For each agent: identify guardrails, forbidden_actions, and behavioral constraints
4. Assess: are current guardrails using positive or negative constraint language?
5. For each positive directive in agent definitions: propose the negative equivalent
6. Apply pattern catalog taxonomy to each proposed change
7. Identify high-value agents to prioritize (those with weakest negative constraint usage)

NEVER make up findings — base all analysis on actual file content read.
Read files in batches (max 500 lines per read per CB-05).

Output: projects/PROJ-014-negative-prompting-research/analysis/agents-analysis.md
Format: table of opportunities (agent / section / current form / proposed negative form / taxonomy type)
plus priority ranking.

AFTER the analyst produces the output, run /adversary C4 quality gate using the 3-agent pipeline:
1. adv-selector: Map C4 criticality to strategy set (all 10 strategies)
2. adv-executor: Execute strategy templates against analysis/agents-analysis.md
3. adv-scorer: Score using S-014 LLM-as-Judge (6-dimension weighted rubric)

Quality threshold: >= 0.95. Maximum 5 iterations.
If score < 0.95: re-invoke ps-analyst-005 with the specific adversary findings to revise.
  NEVER address adversary feedback in the main context — always re-invoke the creator agent.
If score >= 0.95: gate PASSES.
If score < 0.95 after 5 iterations: STOP, escalate to user.

Adversary gate output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/agent-gates/ps-analyst-005-gate.md

Use /worktracker to update TASK-011 status to DONE when gate passes.
```

#### Session 4C: Rules Update Analysis (ps-analyst-006)

```
Use /worktracker to update TASK-012 status to IN PROGRESS.
Project: PROJ-014-negative-prompting-research

Load context:
- projects/PROJ-014-negative-prompting-research/analysis/taxonomy.md
- projects/PROJ-014-negative-prompting-research/decisions/pattern-catalog.md

Use /problem-solving with ps-analyst to analyze Jerry rule files for negative prompting opportunities.

Analysis mission:
1. Use Glob to find all rule files: .context/rules/*.md
2. Read each rule file
3. For each rule: is it expressed as a positive directive (MUST do X) or negative constraint (NEVER do Y)?
4. HARD rules assessment: are they already negative? should they be?
5. MEDIUM rules assessment: positive-to-negative conversion opportunities
6. Identify rules where negative framing would increase precision and reduce ambiguity
7. Note: AE-002 applies — any changes to .context/rules/ are auto-C3+

NEVER make up findings — base all analysis on actual file content read.
Read files in batches (max 500 lines per read per CB-05).

Output: projects/PROJ-014-negative-prompting-research/analysis/rules-analysis.md
Format: rule-by-rule assessment table plus summary of conversion recommendations.
Note auto-escalation risk for any proposed changes.

AFTER the analyst produces the output, run /adversary C4 quality gate using the 3-agent pipeline:
1. adv-selector: Map C4 criticality to strategy set (all 10 strategies)
2. adv-executor: Execute strategy templates against analysis/rules-analysis.md
3. adv-scorer: Score using S-014 LLM-as-Judge (6-dimension weighted rubric)

Quality threshold: >= 0.95. Maximum 5 iterations.
If score < 0.95: re-invoke ps-analyst-006 with the specific adversary findings to revise.
  NEVER address adversary feedback in the main context — always re-invoke the creator agent.
If score >= 0.95: gate PASSES.
If score < 0.95 after 5 iterations: STOP, escalate to user.

Adversary gate output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/agent-gates/ps-analyst-006-gate.md

Use /worktracker to update TASK-012 status to DONE when gate passes.
```

#### Session 4D: Patterns Update Analysis (ps-analyst-007)

```
Use /worktracker to update TASK-013 status to IN PROGRESS.
Project: PROJ-014-negative-prompting-research

Load context:
- projects/PROJ-014-negative-prompting-research/analysis/taxonomy.md
- projects/PROJ-014-negative-prompting-research/decisions/pattern-catalog.md

Use /problem-solving with ps-analyst to analyze Jerry patterns for negative prompting opportunities.

Analysis mission:
1. Use Glob to find pattern-related files:
   - docs/knowledge/*.md
   - Any pattern sections in SKILL.md files (especially orchestration, problem-solving, nasa-se)
   - .context/rules/prompt-quality.md and prompt-templates.md
2. Read each file
3. Identify: workflow patterns, design patterns, anti-patterns currently documented
4. Assess: do pattern descriptions use negative or positive constraint language?
5. Identify: where would "anti-pattern" descriptions benefit from explicit negative prompting?
6. Propose: how should the prompt quality guide be updated to recommend negative prompting?

NEVER make up findings — base all analysis on actual file content read.

Output: projects/PROJ-014-negative-prompting-research/analysis/patterns-analysis.md
Format: pattern-by-pattern assessment plus recommendations for prompt-quality.md and prompt-templates.md.

AFTER the analyst produces the output, run /adversary C4 quality gate using the 3-agent pipeline:
1. adv-selector: Map C4 criticality to strategy set (all 10 strategies)
2. adv-executor: Execute strategy templates against analysis/patterns-analysis.md
3. adv-scorer: Score using S-014 LLM-as-Judge (6-dimension weighted rubric)

Quality threshold: >= 0.95. Maximum 5 iterations.
If score < 0.95: re-invoke ps-analyst-007 with the specific adversary findings to revise.
  NEVER address adversary feedback in the main context — always re-invoke the creator agent.
If score >= 0.95: gate PASSES.
If score < 0.95 after 5 iterations: STOP, escalate to user.

Adversary gate output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/agent-gates/ps-analyst-007-gate.md

Use /worktracker to update TASK-013 status to DONE when gate passes.
```

#### Session 4E: Templates Update Analysis (ps-analyst-008)

```
Use /worktracker to update TASK-014 status to IN PROGRESS.
Project: PROJ-014-negative-prompting-research

Load context:
- projects/PROJ-014-negative-prompting-research/analysis/taxonomy.md
- projects/PROJ-014-negative-prompting-research/decisions/pattern-catalog.md

Use /problem-solving with ps-analyst to analyze Jerry templates for negative prompting opportunities.

Analysis mission:
1. Use Glob to find all template files: .context/templates/**/*
2. Read each template
3. For each template: identify directives, instructions, and behavioral guidance
4. Assess: which template instructions are currently positive directives?
5. For adversarial strategy templates (.context/templates/adversarial/): assess negative prompting alignment
6. For worktracker templates (.context/templates/worktracker/): assess field instruction language
7. Propose concrete negative-prompting rewrites for high-impact templates

NEVER make up findings — base all analysis on actual file content read.

Output: projects/PROJ-014-negative-prompting-research/analysis/templates-analysis.md
Format: template-by-template table plus priority-ranked recommendations.

AFTER the analyst produces the output, run /adversary C4 quality gate using the 3-agent pipeline:
1. adv-selector: Map C4 criticality to strategy set (all 10 strategies)
2. adv-executor: Execute strategy templates against analysis/templates-analysis.md
3. adv-scorer: Score using S-014 LLM-as-Judge (6-dimension weighted rubric)

Quality threshold: >= 0.95. Maximum 5 iterations.
If score < 0.95: re-invoke ps-analyst-008 with the specific adversary findings to revise.
  NEVER address adversary feedback in the main context — always re-invoke the creator agent.
If score >= 0.95: gate PASSES.
If score < 0.95 after 5 iterations: STOP, escalate to user.

Adversary gate output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/agent-gates/ps-analyst-008-gate.md

Use /worktracker to update TASK-014 status to DONE when gate passes.
```

---

### Barrier 4: Application Cross-Pollination + /adversary Quality Gate

**Prerequisites:** TASK-010 through TASK-014 all DONE. All 5 per-agent adversary gates PASSED (>= 0.95).

```
Use /worktracker to update TASK-015 status to IN PROGRESS.
Project: PROJ-014-negative-prompting-research

Verify all 5 QUALITY-GATED analysis files exist:
- projects/PROJ-014-negative-prompting-research/analysis/skills-analysis.md (gated by ps-analyst-004 adversary gate)
- projects/PROJ-014-negative-prompting-research/analysis/agents-analysis.md (gated by ps-analyst-005 adversary gate)
- projects/PROJ-014-negative-prompting-research/analysis/rules-analysis.md (gated by ps-analyst-006 adversary gate)
- projects/PROJ-014-negative-prompting-research/analysis/patterns-analysis.md (gated by ps-analyst-007 adversary gate)
- projects/PROJ-014-negative-prompting-research/analysis/templates-analysis.md (gated by ps-analyst-008 adversary gate)
If any file is missing or any per-agent gate did not pass, STOP and report the blocker.

Use /problem-solving with ps-synthesizer to cross-pollinate all 5 ALREADY GATED application analyses.

Synthesis tasks:
1. Identify cross-domain dependencies (e.g., a rule change that requires an agent change)
2. Identify conflicts: if a rule change contradicts a template recommendation, resolve it
3. Priority ranking: which changes have highest impact across multiple domains?
4. Effort estimation: group changes by implementation effort (trivial / moderate / significant)
5. Sequence: what order should changes be implemented to minimize disruption?
6. Risk assessment: which changes carry highest risk (note AE-002 for rules changes)

Output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/barrier-4/synthesis.md

AFTER the synthesizer produces the output, run /adversary C4 quality gate using the 3-agent pipeline:
1. adv-selector: Map C4 criticality to strategy set (all 10 strategies)
2. adv-executor: Execute strategy templates against barrier-4/synthesis.md
3. adv-scorer: Score using S-014 LLM-as-Judge (6-dimension weighted rubric)

Quality threshold: >= 0.95. Maximum 5 iterations.
Required checks:
- Cross-domain conflicts identified and resolved
- Each recommendation traceable to taxonomy and literature
- Priority ranking is justified with evidence
- Sequence plan accounts for AE-002 escalation risk for rules changes

If score < 0.95: re-invoke ps-synthesizer with the specific adversary findings to revise.
  NEVER address adversary feedback in the main context — always re-invoke the creator agent.
If score >= 0.95: gate PASSES.
If score < 0.95 after 5 iterations: STOP, escalate to user.

/adversary gate output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/barrier-4/adversary-gate.md

Use /worktracker to update TASK-015 status to DONE when gate passes.
```

---

### Phase 5: Implementation Planning (single session, 4 sequential steps)

**Prerequisites:** Barrier 4 gate PASSED.

```
Use /worktracker to update TASK-016 status to IN PROGRESS.
Project: PROJ-014-negative-prompting-research

Load context:
- projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/barrier-4/synthesis.md
- projects/PROJ-014-negative-prompting-research/analysis/skills-analysis.md
- projects/PROJ-014-negative-prompting-research/analysis/agents-analysis.md
- projects/PROJ-014-negative-prompting-research/analysis/rules-analysis.md
- projects/PROJ-014-negative-prompting-research/decisions/pattern-catalog.md

Use /problem-solving with ps-architect to create 4 ADRs in Nygard format.

ADR-014-001: How to apply negative prompting to Jerry skills
Input: analysis/skills-analysis.md + barrier-4 synthesis
Output: decisions/ADR-014-001-skills-negative-prompting.md
Content: Problem, Decision Drivers, Options Considered (with pros/cons), Decision, Rationale, Consequences

ADR-014-002: How to update Jerry agent definitions
Input: analysis/agents-analysis.md + barrier-4 synthesis
Output: decisions/ADR-014-002-agents-negative-prompting.md
Content: same Nygard format

ADR-014-003: How to update Jerry rules
Input: analysis/rules-analysis.md + barrier-4 synthesis
IMPORTANT: Note AE-002 escalation (any .context/rules/ change = auto-C3+)
Output: decisions/ADR-014-003-rules-negative-prompting.md
Content: same Nygard format, must include escalation impact section

ADR-014-004: How to update Jerry patterns and templates
Input: analysis/patterns-analysis.md + analysis/templates-analysis.md + barrier-4 synthesis
Output: decisions/ADR-014-004-patterns-templates-negative-prompting.md
Content: same Nygard format

Each ADR must:
- Document at minimum 2 options considered
- Include explicit trade-off analysis
- Cite evidence from the research phases
- Document consequences (both positive and negative)

AFTER EACH architect produces its ADR, run /adversary C4 quality gate using the 3-agent pipeline:
1. adv-selector: Map C4 criticality to strategy set (all 10 strategies)
2. adv-executor: Execute strategy templates against the ADR
3. adv-scorer: Score using S-014 LLM-as-Judge (6-dimension weighted rubric)

Quality threshold: >= 0.95. Maximum 5 iterations per ADR.
If score < 0.95: re-invoke the specific ps-architect with the adversary findings to revise.
  NEVER address adversary feedback in the main context — always re-invoke the creator agent.
If score >= 0.95: gate PASSES, proceed to next ADR.
If score < 0.95 after 5 iterations: STOP, escalate to user.

Per-agent adversary gate outputs:
- ps-architect-002: orchestration/neg-prompting-20260227-001/agent-gates/ps-architect-002-gate.md
- ps-architect-003: orchestration/neg-prompting-20260227-001/agent-gates/ps-architect-003-gate.md
- ps-architect-004: orchestration/neg-prompting-20260227-001/agent-gates/ps-architect-004-gate.md
- ps-architect-005: orchestration/neg-prompting-20260227-001/agent-gates/ps-architect-005-gate.md

ADR sequence: Each ADR must pass its own /adversary C4 gate BEFORE the next architect starts.
ps-architect-002 -> gate -> PASS -> ps-architect-003 -> gate -> PASS -> ps-architect-004 -> gate -> PASS -> ps-architect-005 -> gate -> PASS

Use /worktracker to update TASK-016 status to DONE when all 4 gates pass.
```

---

### Barrier 5: Implementation Quality Gate

**Prerequisites:** TASK-016 DONE. All 4 ADRs present AND all 4 per-agent adversary gates PASSED (>= 0.95).

```
Use /worktracker to update TASK-017 status to IN PROGRESS.
Project: PROJ-014-negative-prompting-research

Verify all 4 QUALITY-GATED ADR files exist:
- projects/PROJ-014-negative-prompting-research/decisions/ADR-014-001-skills-negative-prompting.md (gated by ps-architect-002 adversary gate)
- projects/PROJ-014-negative-prompting-research/decisions/ADR-014-002-agents-negative-prompting.md (gated by ps-architect-003 adversary gate)
- projects/PROJ-014-negative-prompting-research/decisions/ADR-014-003-rules-negative-prompting.md (gated by ps-architect-004 adversary gate)
- projects/PROJ-014-negative-prompting-research/decisions/ADR-014-004-patterns-templates-negative-prompting.md (gated by ps-architect-005 adversary gate)

Run /adversary C4 quality gate on CROSS-ADR COHERENCE using the 3-agent pipeline:
1. adv-selector: Map C4 criticality to strategy set (all 10 strategies)
2. adv-executor: Execute strategy templates against all 4 gated ADRs together
3. adv-scorer: Score using S-014 LLM-as-Judge (6-dimension weighted rubric)

Criticality: C4. Threshold: >= 0.95. Maximum 5 iterations.

Gate requirements (cross-ADR coherence):
- All ADRs in Nygard format (Problem, Decision Drivers, Options, Decision, Rationale, Consequences)
- Minimum 2 options considered per ADR with explicit trade-offs
- All decisions traceable to evidence from research phases
- Consequences sections cover both positive and negative outcomes
- ADR-014-003 (rules) includes AE-002 escalation impact assessment
- No contradictions between ADR decisions

If score < 0.95: re-invoke the relevant ps-architect(s) with the specific adversary findings to revise.
  NEVER address adversary feedback in the main context — always re-invoke the creator agent.
If score >= 0.95: gate PASSES.
If score < 0.95 after 5 iterations: STOP, escalate to user.

/adversary gate output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/barrier-5/gate.md

Use /worktracker to update TASK-017 status to DONE when gate passes.
```

---

### Phase 6: Final Synthesis + C4 Tournament

**Prerequisites:** Barrier 5 gate PASSED.

```
Use /worktracker to update TASK-018 status to IN PROGRESS.
Project: PROJ-014-negative-prompting-research

Load all artifacts:
- research/academic-survey.md
- research/industry-survey.md
- research/context7-survey.md
- analysis/claim-validation.md
- analysis/comparative.md
- analysis/taxonomy.md
- decisions/pattern-catalog.md
- analysis/skills-analysis.md, agents-analysis.md, rules-analysis.md
- analysis/patterns-analysis.md, templates-analysis.md
- decisions/ADR-014-001 through ADR-014-004

STEP 1: Use /problem-solving with ps-synthesizer for unified final synthesis.
Output: projects/PROJ-014-negative-prompting-research/synthesis/final-synthesis.md
Content:
- Executive summary of the hypothesis verdict
- Evidence summary (50+ sources, key findings)
- Taxonomy of negative prompting patterns with Jerry applicability
- Cross-domain recommendations (skills, agents, rules, patterns, templates)
- Open questions and areas for future research

AFTER ps-synthesizer-004 produces the output, run /adversary C4 quality gate using the 3-agent pipeline:
1. adv-selector: Map C4 criticality to strategy set (all 10 strategies)
2. adv-executor: Execute strategy templates against synthesis/final-synthesis.md
3. adv-scorer: Score using S-014 LLM-as-Judge (6-dimension weighted rubric)

Quality threshold: >= 0.95. Maximum 5 iterations.
If score < 0.95: re-invoke ps-synthesizer-004 with the specific adversary findings to revise.
  NEVER address adversary feedback in the main context — always re-invoke the creator agent.
If score >= 0.95: gate PASSES, proceed to STEP 2.
If score < 0.95 after 5 iterations: STOP, escalate to user.

Adversary gate output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/agent-gates/ps-synthesizer-004-gate.md

STEP 2: Use /problem-solving with ps-architect for implementation roadmap.
Input: GATED synthesis/final-synthesis.md
Output: projects/PROJ-014-negative-prompting-research/synthesis/implementation-roadmap.md
Content:
- Phased implementation plan (Phase 1: quick wins, Phase 2: moderate changes, Phase 3: significant restructuring)
- Priority-ranked change list with effort estimates
- Dependencies between changes
- Risk register with mitigations (including AE-002 escalation plan)

AFTER ps-architect-006 produces the output, run /adversary C4 quality gate using the 3-agent pipeline:
1. adv-selector: Map C4 criticality to strategy set (all 10 strategies)
2. adv-executor: Execute strategy templates against synthesis/implementation-roadmap.md
3. adv-scorer: Score using S-014 LLM-as-Judge (6-dimension weighted rubric)

Quality threshold: >= 0.95. Maximum 5 iterations.
If score < 0.95: re-invoke ps-architect-006 with the specific adversary findings to revise.
  NEVER address adversary feedback in the main context — always re-invoke the creator agent.
If score >= 0.95: gate PASSES, proceed to STEP 3 (C4 Tournament).
If score < 0.95 after 5 iterations: STOP, escalate to user.

Adversary gate output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/agent-gates/ps-architect-006-gate.md

STEP 3: Use /adversary to run C4 TOURNAMENT on GATED final-synthesis.md + GATED implementation-roadmap.md.
The tournament uses the 3-agent pipeline:
1. adv-selector: Map C4 criticality to ALL 10 strategies (full tournament)
2. adv-executor: Execute ALL 10 strategy templates against both gated artifacts
3. adv-scorer: Score using S-014 LLM-as-Judge (6-dimension weighted rubric)

ALL 10 strategies must be executed:
- S-014 LLM-as-Judge (scoring)
- S-003 Steelman Technique
- S-013 Inversion Technique
- S-007 Constitutional AI Critique
- S-002 Devil's Advocate
- S-004 Pre-Mortem Analysis
- S-010 Self-Refine
- S-012 FMEA
- S-011 Chain-of-Verification
- S-001 Red Team Analysis

Score threshold: >= 0.95. Maximum 5 iterations on combined output.
If score < 0.95: re-invoke ps-synthesizer-004 and/or ps-architect-006 with the specific tournament findings to revise.
  NEVER address adversary feedback in the main context — always re-invoke the creator agent.
If score >= 0.95: tournament PASSES.
If score < 0.95 after 5 iterations: STOP, escalate to user.

Tournament output: projects/PROJ-014-negative-prompting-research/orchestration/neg-prompting-20260227-001/adversary/c4-tournament/

Use /worktracker to update TASK-018 and TASK-019 to DONE when tournament passes.
Use /worktracker to mark TASK-020 IN PROGRESS and commit all artifacts.
```

---

## Quality Gate Configuration

### Criticality Assessment: C4 (Critical)

| Factor | Assessment | Rationale |
|--------|-----------|-----------|
| Reversibility | Irreversible | Framework-wide changes to rules, agents, skills |
| File scope | Architecture/governance | Touches .context/rules/ (AE-002), ADRs (AE-003) |
| Impact | Public/constitutional | Changes affect all Jerry agents and users |
| Auto-escalation | AE-002 + AE-003 | Rules changes (AE-002=C3+), new ADRs (AE-003=C3+) |
| Final level | C4 | Framework-wide governance change |

### Per-Agent Adversary Gate Model

Every creator agent output is individually quality-gated BEFORE flowing downstream. This ensures no low-quality output propagates through the pipeline. Barriers receive ALREADY quality-gated inputs and validate cross-artifact coherence rather than individual artifact quality.

**Gate totals:** 17 per-agent gates + 5 barrier synthesis gates + 1 C4 tournament = **23 total quality gates**.

#### 3-Agent Adversary Pipeline

Every quality gate (per-agent and barrier) uses the same 3-agent adversary pipeline:

| Step | Agent | Role | Input | Output |
|------|-------|------|-------|--------|
| 1 | **adv-selector** | Strategy mapper | C4 criticality level | Strategy set (all 10 strategies for C4) |
| 2 | **adv-executor** | Strategy executor | Strategy set + creator artifact | Adversary findings per strategy |
| 3 | **adv-scorer** | Quality scorer | Adversary findings + creator artifact | S-014 LLM-as-Judge score (6-dimension weighted rubric) |

**Gate loop (per-agent):**

```
Creator Agent produces artifact
    |
    v
adv-selector: maps C4 -> all 10 strategies
    |
    v
adv-executor: executes strategy templates against artifact
    |
    v
adv-scorer: S-014 score (6-dimension weighted rubric)
    |
    v
Score >= 0.95? ----YES----> GATE PASSES, artifact flows downstream
    |
    NO (and iteration < 5)
    |
    v
Re-invoke creator agent via Task tool with adversary findings
(NEVER address feedback in main context window)
    |
    v
Creator produces revised artifact -> loop back to adv-selector
    |
    After 5 iterations with no pass: STOP, escalate to user
```

**Gate loop (barrier synthesis):**

Same 3-agent pipeline, but applied to the synthesized cross-artifact output. If the synthesis gate fails, re-invoke the barrier synthesizer (not the upstream creators, which are already individually gated).

#### Owner's Constraints (Non-Negotiable)

| # | Constraint | Enforcement |
|---|-----------|-------------|
| 1 | NEVER allow an upstream creator to proceed without launching /adversary C4 | Per-agent gate on every creator output |
| 2 | NEVER proceed unless the adversary quality is >= 0.95 | Threshold enforced at every gate |
| 3 | NEVER use an unbounded number of iterations | Maximum 5 iterations per gate |
| 4 | NEVER leave feedback unaddressed | Creator re-invocation with specific findings |
| 5 | NEVER use one agent for all adversary strategies | 3-agent pipeline: selector, executor, scorer |
| 6 | NEVER use /adversary only at the end of the orchestration pipeline | Per-agent gates at every creator output |
| 7 | NEVER allow low quality creator outputs downstream | Gate MUST pass before artifact flows |
| 8 | NEVER address the feedback in the main context window | Re-invoke creator via Task tool |

### Required Adversarial Strategies (C4: All 10)

All 10 strategies are applied at EVERY quality gate (per-agent and barrier) because this is a C4 orchestration.

| ID | Strategy | Family | Applied At |
|----|----------|--------|-----------|
| S-014 | LLM-as-Judge | Iterative Self-Correction | All 17 agent gates + all 5 barrier gates + tournament |
| S-003 | Steelman Technique | Dialectical Synthesis | All 17 agent gates + all 5 barrier gates + tournament |
| S-013 | Inversion Technique | Structured Decomposition | All 17 agent gates + all 5 barrier gates + tournament |
| S-007 | Constitutional AI Critique | Iterative Self-Correction | All 17 agent gates + all 5 barrier gates + tournament |
| S-002 | Devil's Advocate | Role-Based Adversarialism | All 17 agent gates + all 5 barrier gates + tournament |
| S-004 | Pre-Mortem Analysis | Role-Based Adversarialism | All 17 agent gates + all 5 barrier gates + tournament |
| S-010 | Self-Refine | Iterative Self-Correction | All 17 agent gates + all 5 barrier gates + tournament |
| S-012 | FMEA | Structured Decomposition | All 17 agent gates + all 5 barrier gates + tournament |
| S-011 | Chain-of-Verification | Structured Decomposition | All 17 agent gates + all 5 barrier gates + tournament |
| S-001 | Red Team Analysis | Role-Based Adversarialism | All 17 agent gates + all 5 barrier gates + tournament |

### Quality Gate Thresholds

#### Per-Agent Gates (17 gates)

| Gate | Creator Agent | Phase | Threshold | Max Iterations | Failure Action |
|------|--------------|-------|-----------|----------------|----------------|
| AG-01 | ps-researcher-001 | 1 (Academic) | >= 0.95 | 5 | Re-invoke ps-researcher-001; escalate at iteration 5 |
| AG-02 | ps-researcher-002 | 1 (Industry) | >= 0.95 | 5 | Re-invoke ps-researcher-002; escalate at iteration 5 |
| AG-03 | ps-researcher-003 | 1 (Context7) | >= 0.95 | 5 | Re-invoke ps-researcher-003; escalate at iteration 5 |
| AG-04 | ps-analyst-001 | 2 (Claims) | >= 0.95 | 5 | Re-invoke ps-analyst-001; escalate at iteration 5 |
| AG-05 | ps-analyst-002 | 2 (Comparative) | >= 0.95 | 5 | Re-invoke ps-analyst-002; escalate at iteration 5 |
| AG-06 | ps-analyst-003 | 3 (Taxonomy) | >= 0.95 | 5 | Re-invoke ps-analyst-003; escalate at iteration 5 |
| AG-07 | ps-architect-001 | 3 (Catalog) | >= 0.95 | 5 | Re-invoke ps-architect-001; escalate at iteration 5 |
| AG-08 | ps-analyst-004 | 4 (Skills) | >= 0.95 | 5 | Re-invoke ps-analyst-004; escalate at iteration 5 |
| AG-09 | ps-analyst-005 | 4 (Agents) | >= 0.95 | 5 | Re-invoke ps-analyst-005; escalate at iteration 5 |
| AG-10 | ps-analyst-006 | 4 (Rules) | >= 0.95 | 5 | Re-invoke ps-analyst-006; escalate at iteration 5 |
| AG-11 | ps-analyst-007 | 4 (Patterns) | >= 0.95 | 5 | Re-invoke ps-analyst-007; escalate at iteration 5 |
| AG-12 | ps-analyst-008 | 4 (Templates) | >= 0.95 | 5 | Re-invoke ps-analyst-008; escalate at iteration 5 |
| AG-13 | ps-architect-002 | 5 (ADR-001) | >= 0.95 | 5 | Re-invoke ps-architect-002; escalate at iteration 5 |
| AG-14 | ps-architect-003 | 5 (ADR-002) | >= 0.95 | 5 | Re-invoke ps-architect-003; escalate at iteration 5 |
| AG-15 | ps-architect-004 | 5 (ADR-003) | >= 0.95 | 5 | Re-invoke ps-architect-004; escalate at iteration 5 |
| AG-16 | ps-architect-005 | 5 (ADR-004) | >= 0.95 | 5 | Re-invoke ps-architect-005; escalate at iteration 5 |
| AG-17 | ps-synthesizer-004 + ps-architect-006 | 6 (Final) | >= 0.95 | 5 | Re-invoke creator; escalate at iteration 5 |

#### Barrier Synthesis Gates (5 gates)

| Gate | Barrier | Validates | Threshold | Max Iterations | Failure Action |
|------|---------|-----------|-----------|----------------|----------------|
| BG-01 | Barrier 1 | Cross-source coherence (3 gated research outputs) | >= 0.95 | 5 | Re-invoke synthesizer; escalate at iteration 5 |
| BG-02 | Barrier 2 | Analysis coherence (2 gated analysis outputs) | >= 0.95 | 5 | Re-invoke synthesizer; escalate at iteration 5 |
| BG-03 | Barrier 3 | Taxonomy-catalog coherence (2 gated outputs) | >= 0.95 | 5 | Re-invoke synthesizer; escalate at iteration 5 |
| BG-04 | Barrier 4 | Cross-domain coherence (5 gated analysis outputs) | >= 0.95 | 5 | Re-invoke synthesizer; escalate at iteration 5 |
| BG-05 | Barrier 5 | Cross-ADR coherence (4 gated ADR outputs) | >= 0.95 | 5 | Re-invoke architect(s); escalate at iteration 5 |

#### C4 Tournament (1 gate)

| Gate | Target | Strategies | Threshold | Max Iterations | Failure Action |
|------|--------|-----------|-----------|----------------|----------------|
| TG-01 | Final synthesis + implementation roadmap | All 10 (full tournament) | >= 0.95 | 5 | Re-invoke synthesizer/architect; escalate at iteration 5 |

#### Gate Metrics Summary

| Metric | Value |
|--------|-------|
| Total quality gates | **23** |
| Per-agent gates | 17 |
| Barrier synthesis gates | 5 |
| C4 tournament gates | 1 |
| Adversary agents per gate | 3 (adv-selector, adv-executor, adv-scorer) |
| Strategies per gate | 10 (all, C4 criticality) |
| Quality threshold | >= 0.95 (uniform) |
| Max iterations per gate | 5 (bounded) |
| Feedback handling | Re-invoke creator via Task tool (NEVER main context) |

### Non-Negotiable Data Source Constraints

Per Issue #122 acceptance criteria:

- NEVER use LLM training data as a source
- NEVER state facts without citations (URL, paper title, library + query)
- ALWAYS use Context7 for library documentation (resolve-library-id then query-docs)
- ALWAYS use WebSearch/WebFetch for web sources
- ALWAYS achieve 50+ unique sources before Barrier 1 passes

---

## Disclaimer

This orchestration plan was generated by orch-planner agent (v2.2.0). It reflects the orchestration design for PROJ-014-negative-prompting-research as of 2026-02-27. Human review recommended before execution. Execution state is authoritative in `ORCHESTRATION.yaml`. All paths are repository-relative and cross-session portable.

*GitHub Issue: [#122](https://github.com/geekatron/jerry/issues/122)*
*Workflow ID: neg-prompting-20260227-001*
*Criticality: C4 (Critical)*
*Quality Threshold: >= 0.95 (all barriers)*
*Orch-Planner Version: 2.2.0*
